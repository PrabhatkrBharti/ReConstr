{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CN_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmrR1yVM8iHD",
        "outputId": "2cbb2cc4-ec44-4986-934d-6adca7a51306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ML/innovation_lab\n"
          ]
        }
      ],
      "source": [
        "# mount google drive (not necessary)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/ML/innovation_lab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "LOADING OUR REVIEW DATASET\n",
        "\"\"\"\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "from nltk.tag import pos_tag\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import math\n",
        "\n",
        "\n",
        "r_df = pd.read_csv('/content/drive/MyDrive/ML/innovation_lab/Final_review_dataset.csv', encoding= 'unicode_escape') # SOURCE PATH TO REVIEW DATASET\n",
        "# print(r_df)\n",
        "\n",
        "c_df = r_df.copy(deep=True)\n",
        "c_df=c_df.drop_duplicates(subset='Text', keep=\"last\")\n",
        "c_df=c_df.reset_index(drop=True)\n",
        "print(c_df)\n",
        "\n",
        "const_list=[]\n",
        "for row in range(len(c_df['Target'])):\n",
        "  if c_df['Target'][row]=='C':\n",
        "    const_list.append(row)\n",
        "print(const_list)\n",
        "print(\"\\nconstructive reviews: {} \\nnon-constructive reviews: {}\".format(len(const_list),len(c_df['Target'])-len(const_list)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw-Hf5xARR3o",
        "outputId": "4b95c079-d29f-4a96-fc2c-b9e18925a292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "                                                   Text Target\n",
            "0     I don't see how your approach has potential to...      N\n",
            "1     It is a bit strange for me that authors have u...      C\n",
            "2     The paper could be considered for acceptance g...      C\n",
            "3     Reviewer 2: The proposal is also poorly writte...      N\n",
            "4     The scientific contribution of this paper - if...      N\n",
            "...                                                 ...    ...\n",
            "1491  The technical contribution is limited as it is...      N\n",
            "1492  After reading the paper, I was confused whethe...      N\n",
            "1493  â¦find one or two male biologists to work wit...      N\n",
            "1494  The authors describe a framework of how to lea...      N\n",
            "1495                 Ok but not good enough - rejection      N\n",
            "\n",
            "[1496 rows x 2 columns]\n",
            "[1, 2, 10, 11, 14, 16, 18, 37, 43, 44, 55, 57, 61, 63, 67, 80, 81, 82, 83, 84, 89, 99, 101, 104, 113, 138, 143, 147, 153, 158, 159, 160, 161, 162, 167, 168, 169, 171, 172, 174, 175, 176, 177, 178, 180, 181, 182, 183, 187, 189, 193, 195, 196, 197, 198, 201, 202, 203, 204, 205, 207, 212, 216, 217, 218, 219, 220, 223, 224, 226, 228, 229, 230, 232, 233, 235, 236, 237, 239, 240, 241, 243, 246, 249, 250, 251, 253, 255, 256, 257, 258, 259, 260, 265, 266, 267, 270, 271, 272, 273, 274, 277, 278, 280, 281, 282, 283, 284, 285, 286, 287, 289, 291, 292, 293, 297, 300, 305, 308, 309, 310, 312, 313, 315, 317, 318, 319, 320, 321, 323, 326, 332, 334, 335, 338, 339, 342, 346, 347, 351, 353, 363, 373, 376, 392, 394, 397, 400, 401, 430, 432, 435, 439, 454, 457, 466, 468, 471, 474, 475, 476, 480, 482, 483, 487, 488, 489, 490, 491, 493, 494, 495, 497, 499, 500, 501, 502, 503, 504, 508, 509, 510, 513, 514, 516, 519, 521, 522, 524, 527, 528, 529, 530, 534, 538, 539, 543, 547, 549, 550, 551, 553, 555, 556, 561, 572, 579, 581, 583, 588, 589, 591, 594, 596, 597, 601, 604, 610, 611, 612, 614, 615, 617, 619, 620, 621, 622, 623, 628, 629, 633, 635, 637, 639, 640, 648, 649, 651, 652, 653, 655, 656, 657, 658, 660, 662, 664, 666, 667, 668, 671, 680, 681, 682, 683, 684, 685, 687, 689, 696, 703, 706, 707, 708, 711, 722, 727, 731, 733, 736, 738, 741, 746, 749, 750, 755, 756, 757, 758, 760, 761, 765, 770, 772, 775, 776, 777, 781, 786, 788, 789, 795, 796, 799, 800, 802, 803, 805, 813, 816, 818, 819, 820, 822, 823, 824, 827, 828, 830, 832, 833, 836, 838, 841, 842, 844, 845, 846, 848, 850, 853, 854, 856, 857, 858, 859, 864, 865, 866, 869, 870, 876, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1431, 1435, 1444, 1469, 1471]\n",
            "\n",
            "constructive reviews: 749 \n",
            "non-constructive reviews: 747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "TEST SENTENCES (for Qualitative Analysis)\n",
        "\"\"\"\n",
        "\n",
        "test_sent=[\"The author's status as a trans person has distorted his view of sex beyond the biological reality.\", #N\n",
        "           \"The experimental protocol used does not provide enough information of the variability of the salience maps shown around small perturbations of adversarial inputs.\", #C - ICLR2018-H1xJjlbAZ-R2_annotated\n",
        "           \"Despite being a woman, the PI was trained by several leading men in the field and is thus likely adequately prepared to lead the proposed research.\", #N\n",
        "           \"the methodological contribution of the paper is minimal, the proposed approach to maintain the budget is simplistic and no theoretical analysis of the proposed algorithm is provided\", #C - ICLR2018-H1Ww66x0--R3_annotated\n",
        "           \"The first author is a woman. She should be in the kitchen, not writing papers.\", #N\n",
        "           \"The author's last name sounds Spanish. I didn't read the manuscript because I'm sure it's full of bad English.\", #N\n",
        "           \"In general, the paper is poorly written, with many notation mistakes and inconsistencies.\", #C - ICLR2018-H1Ww66x0--R2_annotated\n",
        "           \"The authors study design setback the advancement of the field by 20 years.\", #N\n",
        "           \"I said that I'd never again cite or review a paper written by [XX] so it pains me to learn that this is one of their students. God help them.\", #N\n",
        "           \"In Table 1, the results only report the standard deviation of AUC. No standard deviations of nSV and Time are reported.\", #C - ICLR2018-H1Ww66x0--R1_annotated\n",
        "           \"The Information Bottleneck section doesn't feel like an integral part of the paper.\", #C - ICLR2018-SySpa-Z0Z-R1\n",
        "           \"Generally, my feeling is that this work is a little bit too dense, and would like to encourage the authors in this case to make use of the non-strict ICLR page limit, or move some details to appendix and focus more on more thorough explanations.\", #C - ICLR2018-SkhQHMW0W-R1\n",
        "           \"You should look closely at a career outside of science.\", #N\n",
        "           'The phrases I have so far avoided using in this review are, \"lipstick on a pig\", and \"bullshit baffles brains.', #N\n",
        "           \"The manuscript is not well written. There are multiple grammar errors and typos.\", #C - ICLR2018-SJD8YjCpW-R1\n",
        "           \"In particular, the assumption that every token in the SQL statement is either an SQL keyword or appears in the natural language statement is rather atypical and unrealistic.\", #C - ICLR2018-SkYibHlRb-R3\n",
        "           \"This is obviously written by a group from a lower standardized institution based on the quality of work.\", #N\n",
        "           \"The main weakness of this paper is that it does not state the assumptions made and under which conditions these attacks are valid.\", #C - ICLR2018-SkF2D7g0b-R2\n",
        "           \"This person works for an NGO, you shouldn't believe anything they say.\", #N\n",
        "           \"It would be interesting to see a comparison of the results from the parametric and non-parameteric Boo_n versions applied to the test problems.\" #C - ICLR2018-Skx5txzb0W-R2\n",
        "           ]\n",
        "\n",
        "test_sent_labels=['N','C','N','C','N','N','C','N','N','C','C','C','N','N','C','C','N','C','N','C']\n",
        "\n",
        "test_df=pd.DataFrame(list(zip(test_sent, test_sent_labels)), columns =['Text', 'Target'])\n",
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "KYwfAIKNOAUw",
        "outputId": "17cd45cc-0ba4-4990-b019-13f9925d3817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Text Target\n",
              "0   The author's status as a trans person has dist...      N\n",
              "1   The experimental protocol used does not provid...      C\n",
              "2   Despite being a woman, the PI was trained by s...      N\n",
              "3   the methodological contribution of the paper i...      C\n",
              "4   The first author is a woman. She should be in ...      N\n",
              "5   The author's last name sounds Spanish. I didn'...      N\n",
              "6   In general, the paper is poorly written, with ...      C\n",
              "7   The authors study design setback the advanceme...      N\n",
              "8   I said that I'd never again cite or review a p...      N\n",
              "9   In Table 1, the results only report the standa...      C\n",
              "10  The Information Bottleneck section doesn't fee...      C\n",
              "11  Generally, my feeling is that this work is a l...      C\n",
              "12  You should look closely at a career outside of...      N\n",
              "13  The phrases I have so far avoided using in thi...      N\n",
              "14  The manuscript is not well written. There are ...      C\n",
              "15  In particular, the assumption that every token...      C\n",
              "16  This is obviously written by a group from a lo...      N\n",
              "17  The main weakness of this paper is that it doe...      C\n",
              "18  This person works for an NGO, you shouldn't be...      N\n",
              "19  It would be interesting to see a comparison of...      C"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a231ee37-0fda-4b14-b482-edca0e3df35a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The author's status as a trans person has dist...</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The experimental protocol used does not provid...</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Despite being a woman, the PI was trained by s...</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the methodological contribution of the paper i...</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The first author is a woman. She should be in ...</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The author's last name sounds Spanish. I didn'...</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>In general, the paper is poorly written, with ...</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The authors study design setback the advanceme...</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I said that I'd never again cite or review a p...</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>In Table 1, the results only report the standa...</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>The Information Bottleneck section doesn't fee...</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Generally, my feeling is that this work is a l...</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>You should look closely at a career outside of...</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>The phrases I have so far avoided using in thi...</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>The manuscript is not well written. There are ...</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>In particular, the assumption that every token...</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>This is obviously written by a group from a lo...</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>The main weakness of this paper is that it doe...</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>This person works for an NGO, you shouldn't be...</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>It would be interesting to see a comparison of...</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a231ee37-0fda-4b14-b482-edca0e3df35a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a231ee37-0fda-4b14-b482-edca0e3df35a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a231ee37-0fda-4b14-b482-edca0e3df35a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "PREPROCESSING\n",
        "\"\"\"\n",
        "\n",
        "# appending test ICLR dataset to Review dataset for preprocessing\n",
        "frames=[c_df,test_df]\n",
        "c_df = pd.concat(frames,axis=0,ignore_index=True)\n",
        "print(c_df)\n",
        "c_df['Label'] = (c_df['Target']=='C').astype(int)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\n-----------------------------------------------------------------------------------------------------------\\n\\n\")\n",
        "n = 10\n",
        "# original\n",
        "print(\"original sentence: \",c_df['Text'][n])\n",
        "\n",
        "# 1. lower case\n",
        "c_df['clean'] = c_df['Text'].apply(lambda x: x.lower())\n",
        "\n",
        "print(\"lower case: \",c_df['clean'][n])\n",
        "\n",
        "\n",
        "# 2. expand contractions\n",
        "contractions_dict = { \"ain't\": \"are not\", \"'s\":\" is\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \"he'll've\": \"he will have\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\", \"I'm\": \"I am\", \"I've\": \"I have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\", \"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\", \"that'd\": \"that would\", \"that'd've\": \"that would have\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"they'd\": \"they would\", \"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what've\": \"what have\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where've\": \"where have\",\"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who've\": \"who have\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\", \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "added_cont = {\" sry \": \" sorry \", \" & \": \" and \", \" u \": \" you \", \" r \": \" are \", \" 1 \": \" one \", \" 2 \": \" to \", \" 4 \": \" for \", \" ur \": \" you are \", \" pls \": \" please \", \" txt \": \" text \", \"t&c\": \" terms and conditions \", \" k \": \" ok \", \" msg \": \" message \"}\n",
        "contractions_dict.update(added_cont)\n",
        "# Regular expression for finding contractions\n",
        "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
        "def expand_contractions(text,contractions_dict=contractions_dict):\n",
        "    def replace(match):\n",
        "        return contractions_dict[match.group(0)]\n",
        "    return contractions_re.sub(replace, text)\n",
        "# Expanding Contractions in the reviews\n",
        "c_df['clean']=c_df['clean'].apply(lambda x:expand_contractions(x))\n",
        "\n",
        "print(\"expand contradictions: \", c_df['clean'][n])\n",
        "\n",
        "\n",
        "\n",
        "# 3. remove punctuation\n",
        "c_df['clean'] = c_df['clean'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ' , x))\n",
        "\n",
        "print(\"remove punctuation: \", c_df['clean'][n])\n",
        "\n",
        "\n",
        "\n",
        "# 4. again expanding leftover contractions\n",
        "c_df['clean']=c_df['clean'].apply(lambda x:expand_contractions(x))\n",
        "\n",
        "print(\"expanding contractions: \", c_df['clean'][n])\n",
        "\n",
        "\n",
        "\n",
        "# 5. remove words with digits\n",
        "c_df['clean'] = c_df['clean'].apply(lambda x: re.sub('\\S*\\d+\\S*',' ',x))\n",
        "\n",
        "print(\"remove digits: \", c_df['clean'][n])\n",
        "\n",
        "\n",
        "# 6. remove stopwords\n",
        "'''\n",
        "NOTE: Remove Stopwords only for TF-IDF (since it uses non-sequential data)\n",
        "Word2Vec uses sequential data, so for W2V, DO NOT remove stopwords\n",
        "'''\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in stop_words])\n",
        "c_df['stop'] = c_df['clean'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "print(\"remove stopwords: \", c_df['stop'][n])  #for tfidf\n",
        "\n",
        "\n",
        "# 7. lemmatisation\n",
        "'''\n",
        "lemmatization is better than stemming\n",
        "'''\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize_words(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "c_df['stop'] = c_df['stop'].apply(lambda text: lemmatize_words(text))\n",
        "c_df['clean'] = c_df['clean'].apply(lambda text: lemmatize_words(text))\n",
        "\n",
        "print(\"lemmatisation: \", c_df['stop'][n])\n",
        "\n",
        "\n",
        "# 8. again remove stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in stop_words])\n",
        "c_df['stop'] = c_df['stop'].apply(lambda text: lemmatize_words(text))\n",
        "\n",
        "print(\"remove stopwords: \", c_df['stop'][n])  #for tfidf\n",
        "\n",
        "\n",
        "# 9. removal of extra spaces\n",
        "c_df['clean'] = c_df['clean'].apply(lambda x: re.sub(' +', ' ', x))\n",
        "c_df['stop'] = c_df['stop'].apply(lambda x: re.sub(' +', ' ', x))\n",
        "\n",
        "print(\"remove spaces: \", c_df['stop'][n])\n",
        "\n",
        "\n",
        "# 10. tokenization\n",
        "import re\n",
        "def tokenization(text):\n",
        "    tokens = re.split('\\W+',text)\n",
        "    return tokens\n",
        "c_df['token_w2v'] = c_df['clean'].apply(lambda x: tokenization(x))\n",
        "c_df['token_tfidf'] = c_df['stop'].apply(lambda x: tokenization(x))\n",
        "\n",
        "print(\"word2vec tokens: \", c_df['token_w2v'][n])\n",
        "print(\"tfidf tokens: \", c_df['token_tfidf'][n])\n",
        "\n",
        "\n",
        "# 11. word count\n",
        "word_count_list=[]\n",
        "for row in range(len(c_df['Text'])):\n",
        "  word_count_list.append(len(c_df['Text'][row].split()))\n",
        "c_df['word_count']=word_count_list\n",
        "\n",
        "print(\"word count: \", c_df['word_count'][n])\n",
        "\n",
        "\n",
        "# 12. keyword count\n",
        "keyword_count_list=[]\n",
        "for row in range(len(c_df['token_tfidf'])):\n",
        "  keyword_count_list.append(len(c_df['token_tfidf'][row]))\n",
        "c_df['keyword_count']=keyword_count_list\n",
        "\n",
        "print(\"keyword count: \", c_df['keyword_count'][n])\n",
        "\n",
        "\n",
        "# 13. POS count\n",
        "def pos_count(text):\n",
        "  noun_count=0\n",
        "  adj_count=0\n",
        "  verb_count=0\n",
        "  adverb_count=0\n",
        "  tokens = nltk.word_tokenize(text.lower())\n",
        "  text = nltk.Text(tokens)\n",
        "  tags = nltk.pos_tag(text)\n",
        "  from collections import Counter\n",
        "  counts = dict(Counter(tag for word,tag in tags))\n",
        "  for i in list(counts.keys()):\n",
        "    if i[0]=='N':\n",
        "      noun_count+=counts[i]\n",
        "    if i[0]=='J':\n",
        "      adj_count+=counts[i]\n",
        "    if i[0]=='V':\n",
        "      verb_count+=counts[i]\n",
        "    if i[0]=='R':\n",
        "      adverb_count+=counts[i]\n",
        "  return (noun_count, adj_count, verb_count, adverb_count)\n",
        "\n",
        "noun_count_list=[]\n",
        "adj_count_list=[]\n",
        "verb_count_list=[]\n",
        "adverb_count_list=[]\n",
        "for row in range(len(c_df['Text'])):\n",
        "  pos_tup=pos_count(c_df['Text'][row])\n",
        "  noun_count_list.append(pos_tup[0])\n",
        "  adj_count_list.append(pos_tup[1])\n",
        "  verb_count_list.append(pos_tup[2])\n",
        "  adverb_count_list.append(pos_tup[3])\n",
        "c_df['noun_count']=noun_count_list\n",
        "c_df['adj_count']=adj_count_list\n",
        "c_df['verb_count']=verb_count_list\n",
        "c_df['adverb_count']=adverb_count_list\n",
        "\n",
        "print(\"POS counts (noun, adjective, verb, adverb): ({}, {}, {}, {})\".format(c_df['noun_count'][n],c_df['adj_count'][n],c_df['verb_count'][n],c_df['adverb_count'][n]))\n",
        "\n",
        "\n",
        "\n",
        "#VADER sentiment\n",
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "def sentiment_scores(sentence):\n",
        "\tsid_obj = SentimentIntensityAnalyzer()\n",
        "\tsentiment_dict = sid_obj.polarity_scores(sentence)\n",
        "\treturn sentiment_dict\n",
        "\n",
        "neg_list=[]\n",
        "neu_list=[]\n",
        "pos_list=[]\n",
        "compound_list=[]\n",
        "for row in range(len(c_df['Text'])):\n",
        "  senti_dic=sentiment_scores(c_df['Text'][row])\n",
        "  neg_list.append(senti_dic['neg'])\n",
        "  neu_list.append(senti_dic['neu'])\n",
        "  pos_list.append(senti_dic['pos'])\n",
        "  compound_list.append(senti_dic['compound'])\n",
        "c_df['neg'] = neg_list\n",
        "c_df['neu'] = neu_list\n",
        "c_df['pos'] = pos_list\n",
        "c_df['compound'] = compound_list\n",
        "\n",
        "print(\"Sentiment scores (neg, neu, pos, compound): ({}, {}, {}, {})\".format(c_df['neg'][n],c_df['neu'][n],c_df['pos'][n],c_df['compound'][n]))\n",
        "\n",
        "senti_list=[]\n",
        "for row in range(len(c_df['compound'])):\n",
        "  if c_df['compound'][row]>=0.05:\n",
        "    senti_list.append(2)\n",
        "  elif c_df['compound'][row]<=-0.05:\n",
        "    senti_list.append(0)\n",
        "  else:\n",
        "    senti_list.append(1)\n",
        "c_df['sentiment']=senti_list\n",
        "\n",
        "print(\"sentiment class: \", c_df['sentiment'][n])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5dZa71vTCWF",
        "outputId": "9d7799f2-7fed-49bc-ff7d-19c76b1233c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   Text Target\n",
            "0     I don't see how your approach has potential to...      N\n",
            "1     It is a bit strange for me that authors have u...      C\n",
            "2     The paper could be considered for acceptance g...      C\n",
            "3     Reviewer 2: The proposal is also poorly writte...      N\n",
            "4     The scientific contribution of this paper - if...      N\n",
            "...                                                 ...    ...\n",
            "1511  In particular, the assumption that every token...      C\n",
            "1512  This is obviously written by a group from a lo...      N\n",
            "1513  The main weakness of this paper is that it doe...      C\n",
            "1514  This person works for an NGO, you shouldn't be...      N\n",
            "1515  It would be interesting to see a comparison of...      C\n",
            "\n",
            "[1516 rows x 2 columns]\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "original sentence:  The applicant does not address the broader impacts of the proposal, other than its potential benefit to global human health.\n",
            "lower case:  the applicant does not address the broader impacts of the proposal, other than its potential benefit to global human health.\n",
            "expand contradictions:  the applicant does not address the broader impacts of the proposal, other than its potential benefit to global human health.\n",
            "remove punctuation:  the applicant does not address the broader impacts of the proposal  other than its potential benefit to global human health \n",
            "expanding contractions:  the applicant does not address the broader impacts of the proposal  other than its potential benefit to global human health \n",
            "remove digits:  the applicant does not address the broader impacts of the proposal  other than its potential benefit to global human health \n",
            "remove stopwords:  applicant address broader impacts proposal potential benefit global human health\n",
            "lemmatisation:  applicant address broader impact proposal potential benefit global human health\n",
            "remove stopwords:  applicant address broader impact proposal potential benefit global human health\n",
            "remove spaces:  applicant address broader impact proposal potential benefit global human health\n",
            "word2vec tokens:  ['the', 'applicant', 'doe', 'not', 'address', 'the', 'broader', 'impact', 'of', 'the', 'proposal', 'other', 'than', 'it', 'potential', 'benefit', 'to', 'global', 'human', 'health']\n",
            "tfidf tokens:  ['applicant', 'address', 'broader', 'impact', 'proposal', 'potential', 'benefit', 'global', 'human', 'health']\n",
            "word count:  20\n",
            "keyword count:  10\n",
            "POS counts (noun, adjective, verb, adverb): (5, 5, 2, 1)\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.7/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Sentiment scores (neg, neu, pos, compound): (0.0, 0.864, 0.136, 0.4588)\n",
            "sentiment class:  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Creating ToxicBERT features csv file\n",
        "(separate code since running this takes time; for our dataset, approximately 1 hour.\n",
        "if toxicbert.csv already available, no need to run this code; comment it out)\n",
        "\"\"\"\n",
        "# !pip install detoxify\n",
        "# from detoxify import Detoxify\n",
        "\n",
        "# def toxic_res(sentence_list):\n",
        "#   toxicity=[]\n",
        "#   severe_toxicity=[]\n",
        "#   obscene=[]\n",
        "#   threat=[]\n",
        "#   insult=[]\n",
        "#   identity_attack=[]\n",
        "#   # model = Detoxify('original', device='cuda')\n",
        "#   for sentence in sentence_list:\n",
        "#     results = Detoxify('original').predict(sentence)\n",
        "#     toxicity.append(results['toxicity'])\n",
        "#     severe_toxicity.append(results['severe_toxicity'])\n",
        "#     obscene.append(results['obscene'])\n",
        "#     threat.append(results['threat'])\n",
        "#     insult.append(results['insult'])\n",
        "#     identity_attack.append(results['identity_attack'])\n",
        "#   return (toxicity, severe_toxicity, obscene, threat, insult, identity_attack)\n",
        "# toxic_res_list=toxic_res(list(c_df['Text']))\n",
        "# c_df['toxicity'] = toxic_res_list[0]\n",
        "# c_df['severe_toxicity'] = toxic_res_list[1]\n",
        "# c_df['obscene'] = toxic_res_list[2]\n",
        "# c_df['threat'] = toxic_res_list[3]\n",
        "# c_df['insult'] = toxic_res_list[4]\n",
        "# c_df['identity_attack'] = toxic_res_list[5]\n",
        "# print(\"({}, {}, {}, {}, {}, {})\".format(c_df['toxicity'][n],c_df['severe_toxicity'][n],c_df['obscene'][n],c_df['threat'][n],c_df['insult'][n],c_df['identity_attack'][n]))\n",
        "# toxicbert_df = c_df[['Text', 'Target', 'toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack']].copy()\n",
        "# toxicbert_df.to_csv('/content/drive/MyDrive/ML/innovation_lab/testing/toxicbert.csv',index=False) # SAVE PATH FOR TOXICBERT.CSV\n",
        "# toxicbert_df"
      ],
      "metadata": {
        "id": "xdeaHVKsvQch",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8e8bf3e0-b02a-4c5e-c749-f1da138ea2cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCreating ToxicBERT features csv file\\n(separate code since running this takes time; for our dataset, approximately 1 hour.\\nif toxicbert.csv already available, no need to run this code; comment it out)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "k63P3Oh0rXIG",
        "outputId": "5966e8bc-d540-4c6c-d898-524918443a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Text Target  Label  \\\n",
              "0     I don't see how your approach has potential to...      N      0   \n",
              "1     It is a bit strange for me that authors have u...      C      1   \n",
              "2     The paper could be considered for acceptance g...      C      1   \n",
              "3     Reviewer 2: The proposal is also poorly writte...      N      0   \n",
              "4     The scientific contribution of this paper - if...      N      0   \n",
              "...                                                 ...    ...    ...   \n",
              "1511  In particular, the assumption that every token...      C      1   \n",
              "1512  This is obviously written by a group from a lo...      N      0   \n",
              "1513  The main weakness of this paper is that it doe...      C      1   \n",
              "1514  This person works for an NGO, you shouldn't be...      N      0   \n",
              "1515  It would be interesting to see a comparison of...      C      1   \n",
              "\n",
              "                                                  clean  \\\n",
              "0     i do not see how your approach ha potential to...   \n",
              "1     it is a bit strange for me that author have us...   \n",
              "2     the paper could be considered for acceptance g...   \n",
              "3     reviewer to the proposal is also poorly writte...   \n",
              "4     the scientific contribution of this paper if t...   \n",
              "...                                                 ...   \n",
              "1511  in particular the assumption that every token ...   \n",
              "1512  this is obviously written by a group from a lo...   \n",
              "1513  the main weakness of this paper is that it doe...   \n",
              "1514  this person work for an ngo you should not bel...   \n",
              "1515  it would be interesting to see a comparison of...   \n",
              "\n",
              "                                                   stop  \\\n",
              "0     see approach potential shed light question any...   \n",
              "1     bit strange author used python statistical ana...   \n",
              "2     paper could considered acceptance given rewrit...   \n",
              "3     reviewer proposal also poorly written unfocuse...   \n",
              "4     scientific contribution paper best hopelessly ...   \n",
              "...                                                 ...   \n",
              "1511  particular assumption every token sql statemen...   \n",
              "1512  obviously written group lower standardized ins...   \n",
              "1513  main weakness paper state assumption made cond...   \n",
              "1514               person work ngo believe anything say   \n",
              "1515  would interesting see comparison result parame...   \n",
              "\n",
              "                                              token_w2v  \\\n",
              "0     [i, do, not, see, how, your, approach, ha, pot...   \n",
              "1     [it, is, a, bit, strange, for, me, that, autho...   \n",
              "2     [the, paper, could, be, considered, for, accep...   \n",
              "3     [reviewer, to, the, proposal, is, also, poorly...   \n",
              "4     [the, scientific, contribution, of, this, pape...   \n",
              "...                                                 ...   \n",
              "1511  [in, particular, the, assumption, that, every,...   \n",
              "1512  [this, is, obviously, written, by, a, group, f...   \n",
              "1513  [the, main, weakness, of, this, paper, is, tha...   \n",
              "1514  [this, person, work, for, an, ngo, you, should...   \n",
              "1515  [it, would, be, interesting, to, see, a, compa...   \n",
              "\n",
              "                                            token_tfidf  word_count  \\\n",
              "0     [see, approach, potential, shed, light, questi...          18   \n",
              "1     [bit, strange, author, used, python, statistic...          24   \n",
              "2     [paper, could, considered, acceptance, given, ...          20   \n",
              "3     [reviewer, proposal, also, poorly, written, un...          17   \n",
              "4     [scientific, contribution, paper, best, hopele...          19   \n",
              "...                                                 ...         ...   \n",
              "1511  [particular, assumption, every, token, sql, st...          28   \n",
              "1512  [obviously, written, group, lower, standardize...          18   \n",
              "1513  [main, weakness, paper, state, assumption, mad...          23   \n",
              "1514        [person, work, ngo, believe, anything, say]          12   \n",
              "1515  [would, interesting, see, comparison, result, ...          23   \n",
              "\n",
              "      keyword_count  noun_count  adj_count  verb_count  adverb_count    neg  \\\n",
              "0                 8           5          1           5             1  0.000   \n",
              "1                13           7          3           4             1  0.069   \n",
              "2                10           7          0           3             0  0.000   \n",
              "3                10           4          3           3             2  0.130   \n",
              "4                 6           2          2           2             2  0.217   \n",
              "...             ...         ...        ...         ...           ...    ...   \n",
              "1511             16           8          4           3             1  0.000   \n",
              "1512              9           4          2           3             1  0.115   \n",
              "1513              9           6          2           4             1  0.213   \n",
              "1514              6           3          0           3             1  0.000   \n",
              "1515             14           7          2           3             0  0.102   \n",
              "\n",
              "        neu    pos  compound  sentiment  \n",
              "0     1.000  0.000    0.0000          1  \n",
              "1     0.843  0.088    0.1280          2  \n",
              "2     0.864  0.136    0.4588          2  \n",
              "3     0.721  0.149    0.1027          2  \n",
              "4     0.620  0.163   -0.1027          0  \n",
              "...     ...    ...       ...        ...  \n",
              "1511  0.915  0.085    0.3612          2  \n",
              "1512  0.885  0.000   -0.2960          0  \n",
              "1513  0.787  0.000   -0.6908          0  \n",
              "1514  1.000  0.000    0.0000          1  \n",
              "1515  0.795  0.102    0.0000          1  \n",
              "\n",
              "[1516 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e33196f8-bc47-41a9-99eb-d32b19dd7198\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "      <th>Label</th>\n",
              "      <th>clean</th>\n",
              "      <th>stop</th>\n",
              "      <th>token_w2v</th>\n",
              "      <th>token_tfidf</th>\n",
              "      <th>word_count</th>\n",
              "      <th>keyword_count</th>\n",
              "      <th>noun_count</th>\n",
              "      <th>adj_count</th>\n",
              "      <th>verb_count</th>\n",
              "      <th>adverb_count</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>compound</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I don't see how your approach has potential to...</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>i do not see how your approach ha potential to...</td>\n",
              "      <td>see approach potential shed light question any...</td>\n",
              "      <td>[i, do, not, see, how, your, approach, ha, pot...</td>\n",
              "      <td>[see, approach, potential, shed, light, questi...</td>\n",
              "      <td>18</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It is a bit strange for me that authors have u...</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>it is a bit strange for me that author have us...</td>\n",
              "      <td>bit strange author used python statistical ana...</td>\n",
              "      <td>[it, is, a, bit, strange, for, me, that, autho...</td>\n",
              "      <td>[bit, strange, author, used, python, statistic...</td>\n",
              "      <td>24</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.069</td>\n",
              "      <td>0.843</td>\n",
              "      <td>0.088</td>\n",
              "      <td>0.1280</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The paper could be considered for acceptance g...</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>the paper could be considered for acceptance g...</td>\n",
              "      <td>paper could considered acceptance given rewrit...</td>\n",
              "      <td>[the, paper, could, be, considered, for, accep...</td>\n",
              "      <td>[paper, could, considered, acceptance, given, ...</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.864</td>\n",
              "      <td>0.136</td>\n",
              "      <td>0.4588</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Reviewer 2: The proposal is also poorly writte...</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>reviewer to the proposal is also poorly writte...</td>\n",
              "      <td>reviewer proposal also poorly written unfocuse...</td>\n",
              "      <td>[reviewer, to, the, proposal, is, also, poorly...</td>\n",
              "      <td>[reviewer, proposal, also, poorly, written, un...</td>\n",
              "      <td>17</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.130</td>\n",
              "      <td>0.721</td>\n",
              "      <td>0.149</td>\n",
              "      <td>0.1027</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The scientific contribution of this paper - if...</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>the scientific contribution of this paper if t...</td>\n",
              "      <td>scientific contribution paper best hopelessly ...</td>\n",
              "      <td>[the, scientific, contribution, of, this, pape...</td>\n",
              "      <td>[scientific, contribution, paper, best, hopele...</td>\n",
              "      <td>19</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.217</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.163</td>\n",
              "      <td>-0.1027</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1511</th>\n",
              "      <td>In particular, the assumption that every token...</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>in particular the assumption that every token ...</td>\n",
              "      <td>particular assumption every token sql statemen...</td>\n",
              "      <td>[in, particular, the, assumption, that, every,...</td>\n",
              "      <td>[particular, assumption, every, token, sql, st...</td>\n",
              "      <td>28</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.915</td>\n",
              "      <td>0.085</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1512</th>\n",
              "      <td>This is obviously written by a group from a lo...</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>this is obviously written by a group from a lo...</td>\n",
              "      <td>obviously written group lower standardized ins...</td>\n",
              "      <td>[this, is, obviously, written, by, a, group, f...</td>\n",
              "      <td>[obviously, written, group, lower, standardize...</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.115</td>\n",
              "      <td>0.885</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.2960</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>The main weakness of this paper is that it doe...</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>the main weakness of this paper is that it doe...</td>\n",
              "      <td>main weakness paper state assumption made cond...</td>\n",
              "      <td>[the, main, weakness, of, this, paper, is, tha...</td>\n",
              "      <td>[main, weakness, paper, state, assumption, mad...</td>\n",
              "      <td>23</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.213</td>\n",
              "      <td>0.787</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.6908</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>This person works for an NGO, you shouldn't be...</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>this person work for an ngo you should not bel...</td>\n",
              "      <td>person work ngo believe anything say</td>\n",
              "      <td>[this, person, work, for, an, ngo, you, should...</td>\n",
              "      <td>[person, work, ngo, believe, anything, say]</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>It would be interesting to see a comparison of...</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>it would be interesting to see a comparison of...</td>\n",
              "      <td>would interesting see comparison result parame...</td>\n",
              "      <td>[it, would, be, interesting, to, see, a, compa...</td>\n",
              "      <td>[would, interesting, see, comparison, result, ...</td>\n",
              "      <td>23</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.795</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1516 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e33196f8-bc47-41a9-99eb-d32b19dd7198')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e33196f8-bc47-41a9-99eb-d32b19dd7198 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e33196f8-bc47-41a9-99eb-d32b19dd7198');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toxic_df=pd.read_csv('/content/drive/MyDrive/ML/innovation_lab/toxicbert.csv') # SOURCE PATH FOR TOXICBERT.CSV\n",
        "toxic_df=toxic_df.drop_duplicates(subset='Text', keep=\"last\")\n",
        "toxic_df=toxic_df.reset_index(drop=True)\n",
        "toxic_arr=(toxic_df[['toxicity','severe_toxicity','obscene','threat','insult','identity_attack']].copy()).to_numpy()\n",
        "toxic_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9NnC0_krUX-F",
        "outputId": "4e62b3ca-4fcb-4f74-ff66-f4047a9cd067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Text Target  toxicity  \\\n",
              "0     I don't see how your approach has potential to...      N  0.000590   \n",
              "1     It is a bit strange for me that authors have u...      C  0.000579   \n",
              "2     The paper could be considered for acceptance g...      C  0.000510   \n",
              "3     Reviewer 2: The proposal is also poorly writte...      N  0.000629   \n",
              "4     The scientific contribution of this paper - if...      N  0.000744   \n",
              "...                                                 ...    ...       ...   \n",
              "1511  In particular, the assumption that every token...      C  0.000702   \n",
              "1512  This is obviously written by a group from a lo...      N  0.000592   \n",
              "1513  The main weakness of this paper is that it doe...      C  0.003782   \n",
              "1514  This person works for an NGO, you shouldn't be...      N  0.000903   \n",
              "1515  It would be interesting to see a comparison of...      C  0.000588   \n",
              "\n",
              "      severe_toxicity   obscene    threat    insult  identity_attack  \n",
              "0            0.000128  0.000181  0.000131  0.000179         0.000146  \n",
              "1            0.000125  0.000175  0.000134  0.000178         0.000143  \n",
              "2            0.000141  0.000194  0.000139  0.000184         0.000152  \n",
              "3            0.000122  0.000175  0.000127  0.000185         0.000145  \n",
              "4            0.000114  0.000173  0.000118  0.000188         0.000146  \n",
              "...               ...       ...       ...       ...              ...  \n",
              "1511         0.000116  0.000172  0.000124  0.000180         0.000144  \n",
              "1512         0.000125  0.000177  0.000126  0.000182         0.000140  \n",
              "1513         0.000092  0.000247  0.000141  0.000267         0.000201  \n",
              "1514         0.000107  0.000162  0.000123  0.000176         0.000149  \n",
              "1515         0.000125  0.000182  0.000130  0.000179         0.000142  \n",
              "\n",
              "[1516 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-904e1de7-fdba-4f74-933f-32321df1d4b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "      <th>toxicity</th>\n",
              "      <th>severe_toxicity</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_attack</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I don't see how your approach has potential to...</td>\n",
              "      <td>N</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>0.000179</td>\n",
              "      <td>0.000146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It is a bit strange for me that authors have u...</td>\n",
              "      <td>C</td>\n",
              "      <td>0.000579</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>0.000175</td>\n",
              "      <td>0.000134</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>0.000143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The paper could be considered for acceptance g...</td>\n",
              "      <td>C</td>\n",
              "      <td>0.000510</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.000194</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.000184</td>\n",
              "      <td>0.000152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Reviewer 2: The proposal is also poorly writte...</td>\n",
              "      <td>N</td>\n",
              "      <td>0.000629</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.000175</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.000185</td>\n",
              "      <td>0.000145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The scientific contribution of this paper - if...</td>\n",
              "      <td>N</td>\n",
              "      <td>0.000744</td>\n",
              "      <td>0.000114</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>0.000188</td>\n",
              "      <td>0.000146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1511</th>\n",
              "      <td>In particular, the assumption that every token...</td>\n",
              "      <td>C</td>\n",
              "      <td>0.000702</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000180</td>\n",
              "      <td>0.000144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1512</th>\n",
              "      <td>This is obviously written by a group from a lo...</td>\n",
              "      <td>N</td>\n",
              "      <td>0.000592</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>0.000140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>The main weakness of this paper is that it doe...</td>\n",
              "      <td>C</td>\n",
              "      <td>0.003782</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>0.000247</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.000267</td>\n",
              "      <td>0.000201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>This person works for an NGO, you shouldn't be...</td>\n",
              "      <td>N</td>\n",
              "      <td>0.000903</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>It would be interesting to see a comparison of...</td>\n",
              "      <td>C</td>\n",
              "      <td>0.000588</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.000179</td>\n",
              "      <td>0.000142</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1516 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-904e1de7-fdba-4f74-933f-32321df1d4b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-904e1de7-fdba-4f74-933f-32321df1d4b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-904e1de7-fdba-4f74-933f-32321df1d4b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Features array (a matrix of all the 16 features, other than word embedding)\n",
        "\n",
        "features_arr = (c_df[['word_count', 'keyword_count', 'noun_count', 'adj_count', 'verb_count', 'adverb_count', 'neg', 'neu', 'pos', 'sentiment']].copy()).to_numpy()\n",
        "print(features_arr.shape, type(features_arr))\n",
        "\n",
        "features_arr=np.column_stack((features_arr,toxic_arr))\n",
        "print(features_arr.shape, type(features_arr))\n",
        "\n",
        "iclr_arr=features_arr[-len(test_df['Text']):]\n",
        "print(features_arr.shape, iclr_arr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "882McRX5UlPQ",
        "outputId": "ae35a8a2-4cb5-4c5b-eb3a-b311a123239e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1516, 10) <class 'numpy.ndarray'>\n",
            "(1516, 16) <class 'numpy.ndarray'>\n",
            "(1516, 16) (20, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "INITIALISATION\n",
        "\"\"\"\n",
        "# Setting parameters for randomness seed and split ratio\n",
        "seed = 1\n",
        "split_ratio = 0.2\n",
        "\n",
        "\n",
        "# Initialising empty lists to store our model results data\n",
        "model_name=[]\n",
        "acc_iclr=[]\n",
        "acc_test=[]\n",
        "auc_iclr=[]\n",
        "auc_test=[]\n",
        "prec_iclr=[]\n",
        "prec_test=[]\n",
        "rec_iclr=[]\n",
        "rec_test=[]\n",
        "f1_iclr=[]\n",
        "f1_test=[]\n",
        "MNB_res=[]\n",
        "SVC_res=[]\n",
        "XGB_res=[]\n",
        "FNN_res=[]\n",
        "LSTM_res=[]\n",
        "BERT_res=[]\n",
        "comparison=[]\n",
        "qualitative=[]"
      ],
      "metadata": {
        "id": "ljl1lvPcUqDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "SVM and Multinomial Naive Bayes\n",
        "\"\"\"\n",
        "# importing necessary modules\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import random\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# preprocessing for tfidf\n",
        "def pre_process(text):\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
        "    words = \"\"\n",
        "    for i in text:\n",
        "            stemmer = SnowballStemmer(\"english\")\n",
        "            words += (stemmer.stem(i))+\" \"\n",
        "    return words\n",
        "\n",
        "# creating tfidf feature vector matrix\n",
        "textFeatures = c_df['Text'].copy()\n",
        "textFeatures = textFeatures.apply(pre_process)\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "features = vectorizer.fit_transform(textFeatures)\n",
        "labels = c_df['Label']\n",
        "\n",
        "# appending other features matrix to tfidf matrix\n",
        "print(type(features),features.shape,features[1])\n",
        "features=features.toarray()\n",
        "features=np.column_stack((features,features_arr))\n",
        "print(type(features),features.shape,features[1])\n",
        "\n",
        "#splitting features matrix and labels into train and test\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features[:-len(test_df['Text'])], labels[:-len(test_df['Text'])], test_size = split_ratio, random_state = seed)\n",
        "\n",
        "# oversampling training dataset using SMOTE to ensure balanced classes\n",
        "print(type(features_train),features_train.shape,features_train[1])\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 2)\n",
        "features_train, labels_train = sm.fit_resample(features_train, labels_train.ravel())\n",
        "print(type(features_train),features_train.shape,features_train[1])\n",
        "\n",
        "# extracting the iclr features and labels for qualitative analysis\n",
        "features_iclr=features[-len(test_df['Text']):]\n",
        "labels_iclr=labels[-len(test_df['Text']):]\n",
        "print(type(features_iclr),features_iclr.shape,features_iclr[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR2m1m_5leFq",
        "outputId": "7ba97ca5-d453-4c4e-b7db-50b1e50acb2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'> (1516, 3003)   (0, 968)\t0.22035412273224164\n",
            "  (0, 1973)\t0.24527734671487517\n",
            "  (0, 2846)\t0.28929660722564116\n",
            "  (0, 1594)\t0.36661515283444923\n",
            "  (0, 2499)\t0.36661515283444923\n",
            "  (0, 1376)\t0.255997322127599\n",
            "  (0, 168)\t0.24339315567195033\n",
            "  (0, 2520)\t0.255997322127599\n",
            "  (0, 2095)\t0.3471363197512718\n",
            "  (0, 2841)\t0.18939875193151473\n",
            "  (0, 269)\t0.1307846527995809\n",
            "  (0, 2542)\t0.3471363197512718\n",
            "  (0, 350)\t0.23341801244228072\n",
            "<class 'numpy.ndarray'> (1516, 3019) [0.         0.         0.         ... 0.00013358 0.00017784 0.00014292]\n",
            "<class 'numpy.ndarray'> (1196, 3019) [0.         0.         0.         ... 0.00011524 0.00017741 0.00014336]\n",
            "<class 'numpy.ndarray'> (1202, 3019) [0.         0.         0.         ... 0.00011524 0.00017741 0.00014336]\n",
            "<class 'numpy.ndarray'> (20, 3019) [0.         0.         0.         ... 0.00012589 0.00017843 0.0001438 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# size of features and labels for train, test(baseline) and iclr\n",
        "print(features.shape, c_df['Label'].shape)\n",
        "print(features_train.shape, features_test.shape, features_iclr.shape)\n",
        "print(labels_train.shape, labels_test.shape, labels_iclr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxWbO5f7mSjl",
        "outputId": "8cc97bb0-2c5e-48f6-8a62-2beab98c3192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1516, 3019) (1516,)\n",
            "(1202, 3019) (300, 3019) (20, 3019)\n",
            "(1202,) (300,) (20,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # finding SVM hyperparameter - gamma\n",
        "# from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score,roc_auc_score\n",
        "# from sklearn.svm import SVC\n",
        "\n",
        "# g_lst = []\n",
        "# s_acc_lst = []\n",
        "# s_f1_lst=[]\n",
        "\n",
        "\n",
        "# for i in range(1,100):\n",
        "#   g=i/10\n",
        "#   svc = SVC(kernel='linear', gamma=g,)\n",
        "#   svc.fit(features_train, labels_train)\n",
        "#   prediction = svc.predict(features_train)\n",
        "#   g_lst.append(g)\n",
        "#   s_acc_lst.append(accuracy_score(labels_train,prediction))\n",
        "#   s_f1_lst.append(f1_score(labels_train,prediction))\n",
        "\n",
        "# g_arr=np.array(g_lst)\n",
        "# s_acc_arr=np.array(s_acc_lst)\n",
        "# s_f1_arr=np.array(s_f1_lst)\n",
        "\n",
        "# for i in range(len(g_lst)):\n",
        "#   print(g_lst[i],s_acc_lst[i],s_f1_lst[i])\n",
        "\n",
        "# plt.plot(g_lst,s_acc_lst,color='green')\n",
        "# plt.plot(g_lst,s_f1_lst,color='blue')\n",
        "# plt.xlabel('gamma')\n",
        "# plt.ylabel('scores')\n",
        "# plt.legend(['accuracy score','f1 score'])\n",
        "# plt.title('SVM Model')\n",
        "# plt.show()\n",
        "\n",
        "# print(g_arr[max(range(len(s_acc_lst)), key=s_acc_lst.__getitem__)],g_arr[max(range(len(s_f1_lst)), key=s_f1_lst.__getitem__)])"
      ],
      "metadata": {
        "id": "rh_05LYFmfvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"SVM\"\"\"\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, roc_auc_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#hyperparameters\n",
        "g=2 #training:0.9;testing:0.9\n",
        "\n",
        "#fit model on training data\n",
        "svc = SVC(kernel='linear', gamma=g)\n",
        "svc.fit(features_train, labels_train)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"SVM BASELINE\"\"\"\n",
        "print(\"\\n\\nSVM Baseline\")\n",
        "\n",
        "prediction = svc.predict(features_test)\n",
        "accuracy_score(labels_test,prediction)\n",
        "print(prediction,accuracy_score(labels_test,prediction))\n",
        "\n",
        "print(labels_test.to_numpy())\n",
        "\n",
        "comparison.append(('SVM_params',accuracy_score(labels_test,prediction)))\n",
        "print(\"accuracy: \",accuracy_score(labels_test,prediction))\n",
        "print(\"precision: \",precision_score(labels_test,prediction))\n",
        "print(\"f1 score: \",f1_score(labels_test,prediction))\n",
        "print(\"recall: \",recall_score(labels_test,prediction))\n",
        "print(\"roc_auc score: \",roc_auc_score(labels_test,prediction))\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"SVM QUALITATIVE ANALYSIS\"\"\"\n",
        "print(\"\\n\\nSVM Qualitative\")\n",
        "\n",
        "pred_iclr = svc.predict(features_iclr)\n",
        "accuracy_score(labels_iclr,pred_iclr)\n",
        "print(pred_iclr,accuracy_score(labels_iclr,pred_iclr))\n",
        "\n",
        "print(labels_iclr.to_numpy())\n",
        "\n",
        "qualitative.append(('SVM_params',accuracy_score(labels_iclr,pred_iclr)))\n",
        "print(\"accuracy: \",accuracy_score(labels_iclr,pred_iclr))\n",
        "print(\"precision: \",precision_score(labels_iclr,pred_iclr))\n",
        "print(\"f1 score: \",f1_score(labels_iclr,pred_iclr))\n",
        "print(\"recall: \",recall_score(labels_iclr,pred_iclr))\n",
        "print(\"roc_auc score: \",roc_auc_score(labels_iclr,pred_iclr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m5z9wK9mpGu",
        "outputId": "37f846f3-7487-4f42-e817-33ffddc483dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "SVM Baseline\n",
            "[0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 0\n",
            " 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1\n",
            " 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 1 0 1\n",
            " 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0\n",
            " 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 1 0\n",
            " 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1\n",
            " 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1\n",
            " 0 1 0 0] 0.75\n",
            "[0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0\n",
            " 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1\n",
            " 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 0\n",
            " 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0\n",
            " 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0\n",
            " 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1\n",
            " 1 1 0 0]\n",
            "accuracy:  0.75\n",
            "precision:  0.762589928057554\n",
            "f1 score:  0.7386759581881532\n",
            "recall:  0.7162162162162162\n",
            "roc_auc score:  0.7495554765291608\n",
            "\n",
            "\n",
            "SVM Qualitative\n",
            "[0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1] 0.9\n",
            "[0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1]\n",
            "accuracy:  0.9\n",
            "precision:  1.0\n",
            "f1 score:  0.888888888888889\n",
            "recall:  0.8\n",
            "roc_auc score:  0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "APPEND\n",
        "\"\"\"\n",
        "model_name.append(\"Support Vector Classifier\")\n",
        "\n",
        "#test\n",
        "acc_t = acc_test.append(accuracy_score(labels_test,prediction))\n",
        "auc_t = auc_test.append(roc_auc_score(labels_test,prediction))\n",
        "prec_t = prec_test.append(precision_score(labels_test,prediction))\n",
        "rec_t = rec_test.append(recall_score(labels_test,prediction))\n",
        "f1_t = f1_test.append(f1_score(labels_test,prediction))\n",
        "\n",
        "#iclr\n",
        "acc_i = acc_iclr.append(accuracy_score(labels_iclr,pred_iclr))\n",
        "auc_i = auc_iclr.append(roc_auc_score(labels_iclr,pred_iclr))\n",
        "prec_i = prec_iclr.append(precision_score(labels_iclr,pred_iclr))\n",
        "rec_i = rec_iclr.append(recall_score(labels_iclr,pred_iclr))\n",
        "f1_i = f1_iclr.append(f1_score(labels_iclr,pred_iclr))\n",
        "\n",
        "SVC_res=[accuracy_score(labels_test,prediction),accuracy_score(labels_iclr,pred_iclr),roc_auc_score(labels_test,prediction),roc_auc_score(labels_iclr,pred_iclr),\n",
        "          precision_score(labels_test,prediction),precision_score(labels_iclr,pred_iclr),recall_score(labels_test,prediction),recall_score(labels_iclr,pred_iclr),\n",
        "          f1_score(labels_test,prediction),f1_score(labels_iclr,pred_iclr)]"
      ],
      "metadata": {
        "id": "wq4AyxSmorDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # finding MNB hyperparameter - alpha\n",
        "# from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, roc_auc_score\n",
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# a_lst = []\n",
        "# s_acc_lst = []\n",
        "# s_f1_lst=[]\n",
        "\n",
        "# for i in range(0,1000):\n",
        "#   a=i/100\n",
        "#   mnb = MultinomialNB(alpha=a)\n",
        "#   mnb.fit(features_train, labels_train)\n",
        "#   prediction = mnb.predict(features_train)\n",
        "#   a_lst.append(a)\n",
        "#   s_acc_lst.append(accuracy_score(labels_train,prediction))\n",
        "#   s_f1_lst.append(f1_score(labels_train,prediction))\n",
        "\n",
        "# a_arr=np.array(a_lst)\n",
        "# s_acc_arr=np.array(s_acc_lst)\n",
        "# s_f1_arr=np.array(s_f1_lst)\n",
        "\n",
        "# for i in range(len(a_lst)):\n",
        "#   print(a_lst[i],s_acc_lst[i],s_f1_lst[i])\n",
        "\n",
        "# plt.plot(a_lst,s_acc_lst,color='green')\n",
        "# plt.plot(a_lst,s_f1_lst,color='blue')\n",
        "# plt.xlabel('gamma')\n",
        "# plt.ylabel('scores')\n",
        "# plt.legend(['accuracy score','f1 score'])\n",
        "# plt.title('MNB Model')\n",
        "# plt.show()\n",
        "\n",
        "# print(a_arr[max(range(len(s_acc_lst)), key=s_acc_lst.__getitem__)],a_arr[max(range(len(s_f1_lst)), key=s_f1_lst.__getitem__)])"
      ],
      "metadata": {
        "id": "Si1yp08Uotuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"MNB\"\"\"\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#hyperparameters\n",
        "a=0.29 #training:0.0;testing:0.29\n",
        "\n",
        "#fit model on training data\n",
        "mnb = MultinomialNB(alpha=a)\n",
        "mnb.fit(features_train, labels_train)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"MNB BASELINE\"\"\"\n",
        "print(\"\\n\\nMNB Baseline\")\n",
        "\n",
        "prediction = mnb.predict(features_test)\n",
        "accuracy_score(labels_test,prediction)\n",
        "print(prediction,accuracy_score(labels_test,prediction))\n",
        "\n",
        "print(labels_test.to_numpy())\n",
        "\n",
        "comparison.append(('MNB_params',accuracy_score(labels_test,prediction)))\n",
        "print(\"accuracy: \",accuracy_score(labels_test,prediction))\n",
        "print(\"precision: \",precision_score(labels_test,prediction))\n",
        "print(\"f1 score: \",f1_score(labels_test,prediction))\n",
        "print(\"recall: \",recall_score(labels_test,prediction))\n",
        "print(\"roc_auc score: \",roc_auc_score(labels_test,prediction))\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"MNB QUALITATIVE ANALYSIS\"\"\"\n",
        "print(\"\\n\\nMNB Qualitative\")\n",
        "\n",
        "pred_iclr = mnb.predict(features_iclr)\n",
        "accuracy_score(labels_iclr,pred_iclr)\n",
        "print(pred_iclr,accuracy_score(labels_iclr,pred_iclr))\n",
        "\n",
        "print(labels_iclr.to_numpy())\n",
        "\n",
        "qualitative.append(('MNB_params',accuracy_score(labels_iclr,pred_iclr)))\n",
        "print(\"accuracy: \",accuracy_score(labels_iclr,pred_iclr))\n",
        "print(\"precision: \",precision_score(labels_iclr,pred_iclr))\n",
        "print(\"f1 score: \",f1_score(labels_iclr,pred_iclr))\n",
        "print(\"recall: \",recall_score(labels_iclr,pred_iclr))\n",
        "print(\"roc_auc score: \",roc_auc_score(labels_iclr,pred_iclr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOhWp37-rxZ_",
        "outputId": "420d8dec-48f3-4323-fcb1-caba9b8e252a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "MNB Baseline\n",
            "[1 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0\n",
            " 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1\n",
            " 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 1 0 1\n",
            " 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0\n",
            " 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0\n",
            " 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1\n",
            " 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1\n",
            " 0 1 0 0] 0.7466666666666667\n",
            "[0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0\n",
            " 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1\n",
            " 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 0\n",
            " 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0\n",
            " 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0\n",
            " 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1\n",
            " 1 1 0 0]\n",
            "accuracy:  0.7466666666666667\n",
            "precision:  0.702247191011236\n",
            "f1 score:  0.7668711656441718\n",
            "recall:  0.8445945945945946\n",
            "roc_auc score:  0.7479551920341395\n",
            "\n",
            "\n",
            "MNB Qualitative\n",
            "[0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1] 0.95\n",
            "[0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1]\n",
            "accuracy:  0.95\n",
            "precision:  1.0\n",
            "f1 score:  0.9473684210526316\n",
            "recall:  0.9\n",
            "roc_auc score:  0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "APPEND\n",
        "\"\"\"\n",
        "model_name.append(\"Multinomial Naive Bayes\")\n",
        "\n",
        "#test\n",
        "acc_t = acc_test.append(accuracy_score(labels_test,prediction))\n",
        "auc_t = auc_test.append(roc_auc_score(labels_test,prediction))\n",
        "prec_t = prec_test.append(precision_score(labels_test,prediction))\n",
        "rec_t = rec_test.append(recall_score(labels_test,prediction))\n",
        "f1_t = f1_test.append(f1_score(labels_test,prediction))\n",
        "\n",
        "#iclr\n",
        "acc_i = acc_iclr.append(accuracy_score(labels_iclr,pred_iclr))\n",
        "auc_i = auc_iclr.append(roc_auc_score(labels_iclr,pred_iclr))\n",
        "prec_i = prec_iclr.append(precision_score(labels_iclr,pred_iclr))\n",
        "rec_i = rec_iclr.append(recall_score(labels_iclr,pred_iclr))\n",
        "f1_i = f1_iclr.append(f1_score(labels_iclr,pred_iclr))\n",
        "\n",
        "MNB_res=[accuracy_score(labels_test,prediction),accuracy_score(labels_iclr,pred_iclr),roc_auc_score(labels_test,prediction),roc_auc_score(labels_iclr,pred_iclr),\n",
        "          precision_score(labels_test,prediction),precision_score(labels_iclr,pred_iclr),recall_score(labels_test,prediction),recall_score(labels_iclr,pred_iclr),\n",
        "          f1_score(labels_test,prediction),f1_score(labels_iclr,pred_iclr)]"
      ],
      "metadata": {
        "id": "gXzHzIO7tNlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "XGBoost\n",
        "\"\"\"\n",
        "# importing libraries\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, roc_auc_score\n",
        "\n",
        "# create tfidf features\n",
        "tfidf = TfidfVectorizer(max_features = 3000)\n",
        "X = tfidf.fit_transform(c_df['stop']).toarray()\n",
        "y = c_df['Label'].values\n",
        "\n",
        "# append other features to tfidf feature matrix\n",
        "print(type(X),X.shape,X[1])\n",
        "X=np.column_stack((X,features_arr))\n",
        "print(type(X),X.shape,X[1])\n",
        "\n",
        "# split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X[:-len(test_df['Text'])], y[:-len(test_df['Text'])], test_size = split_ratio, random_state = seed)\n",
        "\n",
        "# oversampling training data using SMOTE\n",
        "print(type(X_train),X_train.shape,X_train[1])\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 2)\n",
        "X_train, y_train = sm.fit_resample(X_train, y_train.ravel())\n",
        "print(type(X_train),X_train.shape,X_train[1])\n",
        "\n",
        "# creating iclr data\n",
        "X_iclr=X[-len(test_df['Text']):]\n",
        "y_iclr=y[-len(test_df['Text']):]\n",
        "\n",
        "# fit model on training data\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(model)\n",
        "\n",
        "\"\"\"XGB BASELINE\"\"\"\n",
        "print(\"\\n\\nXGB Baseline\")\n",
        "\n",
        "prediction = model.predict(X_test)\n",
        "accuracy_score(y_test,prediction)\n",
        "print(prediction,accuracy_score(y_test,prediction))\n",
        "\n",
        "\n",
        "print(y_test)\n",
        "\n",
        "comparison.append(('XGB',accuracy_score(y_test,prediction)))\n",
        "print(\"accuracy: \",accuracy_score(y_test,prediction))\n",
        "print(\"precision: \",precision_score(y_test,prediction))\n",
        "print(\"f1 score: \",f1_score(y_test,prediction))\n",
        "print(\"recall: \",recall_score(y_test,prediction))\n",
        "print(\"roc_auc score: \",roc_auc_score(y_test,prediction))\n",
        "\n",
        "\n",
        "\"\"\"XGB QUALITATIVE ANALYSIS\"\"\"\n",
        "print(\"\\n\\nXGB Qualitative\")\n",
        "\n",
        "pred_iclr = model.predict(X_iclr)\n",
        "accuracy_score(y_iclr,pred_iclr)\n",
        "print(pred_iclr,accuracy_score(y_iclr,pred_iclr))\n",
        "\n",
        "print(y_iclr)\n",
        "\n",
        "qualitative.append(('XGB',accuracy_score(y_iclr,pred_iclr)))\n",
        "print(\"accuracy: \",accuracy_score(y_iclr,pred_iclr))\n",
        "print(\"precision: \",precision_score(y_iclr,pred_iclr))\n",
        "print(\"f1 score: \",f1_score(y_iclr,pred_iclr))\n",
        "print(\"recall: \",recall_score(y_iclr,pred_iclr))\n",
        "print(\"roc_auc score: \",roc_auc_score(y_iclr,pred_iclr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EoSVp8_tv7F",
        "outputId": "4ddd397b-5a7d-4e38-a890-9d74367e82ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> (1516, 3000) [0. 0. 0. ... 0. 0. 0.]\n",
            "<class 'numpy.ndarray'> (1516, 3016) [0.         0.         0.         ... 0.00013358 0.00017784 0.00014292]\n",
            "<class 'numpy.ndarray'> (1196, 3016) [0.         0.         0.         ... 0.00011524 0.00017741 0.00014336]\n",
            "<class 'numpy.ndarray'> (1202, 3016) [0.         0.         0.         ... 0.00011524 0.00017741 0.00014336]\n",
            "XGBClassifier()\n",
            "\n",
            "\n",
            "XGB Baseline\n",
            "[0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1\n",
            " 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1\n",
            " 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0 1\n",
            " 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 0 1 0\n",
            " 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0\n",
            " 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1\n",
            " 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 1 1 0 1 1\n",
            " 0 1 0 0] 0.7733333333333333\n",
            "[0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0\n",
            " 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1\n",
            " 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 0\n",
            " 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0\n",
            " 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0\n",
            " 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1\n",
            " 1 1 0 0]\n",
            "accuracy:  0.7733333333333333\n",
            "precision:  0.7531645569620253\n",
            "f1 score:  0.7777777777777778\n",
            "recall:  0.8040540540540541\n",
            "roc_auc score:  0.7737375533428165\n",
            "\n",
            "\n",
            "XGB Qualitative\n",
            "[0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1] 0.75\n",
            "[0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1]\n",
            "accuracy:  0.75\n",
            "precision:  0.8571428571428571\n",
            "f1 score:  0.7058823529411764\n",
            "recall:  0.6\n",
            "roc_auc score:  0.7500000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# size of features and labels for train, test(baseline) and iclr\n",
        "print(X.shape, y.shape)\n",
        "print(X_train.shape, X_test.shape, X_iclr.shape)\n",
        "print(y_train.shape, y_test.shape, y_iclr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF_6yCH3ukEO",
        "outputId": "7f16a513-aae9-46ea-f7aa-3819a494908e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1516, 3016) (1516,)\n",
            "(1202, 3016) (300, 3016) (20, 3016)\n",
            "(1202,) (300,) (20,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "APPEND\n",
        "\"\"\"\n",
        "model_name.append(\"XGBoost\")\n",
        "\n",
        "#test\n",
        "acc_t = acc_test.append(accuracy_score(y_test,prediction))\n",
        "auc_t = auc_test.append(roc_auc_score(y_test,prediction))\n",
        "prec_t = prec_test.append(precision_score(y_test,prediction))\n",
        "rec_t = rec_test.append(recall_score(y_test,prediction))\n",
        "f1_t = f1_test.append(f1_score(y_test,prediction))\n",
        "\n",
        "#iclr\n",
        "acc_i = acc_iclr.append(accuracy_score(y_iclr,pred_iclr))\n",
        "auc_i = auc_iclr.append(roc_auc_score(y_iclr,pred_iclr))\n",
        "prec_i = prec_iclr.append(precision_score(y_iclr,pred_iclr))\n",
        "rec_i = rec_iclr.append(recall_score(y_iclr,pred_iclr))\n",
        "f1_i = f1_iclr.append(f1_score(y_iclr,pred_iclr))\n",
        "\n",
        "XGB_res=[accuracy_score(y_test,prediction),accuracy_score(y_iclr,pred_iclr),roc_auc_score(y_test,prediction),roc_auc_score(y_iclr,pred_iclr),\n",
        "          precision_score(y_test,prediction),precision_score(y_iclr,pred_iclr),recall_score(y_test,prediction),recall_score(y_iclr,pred_iclr),\n",
        "          f1_score(y_test,prediction),f1_score(y_iclr,pred_iclr)]"
      ],
      "metadata": {
        "id": "OEDNaWelumNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FO3txLbtwblx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DxYtxg4RwbiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "FEED FORWARD NEURAL NETWORK\n",
        "\"\"\"\n",
        "\n",
        "# Load libraries\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from sklearn.pipeline import Pipeline\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, roc_auc_score\n",
        "\n",
        "# Set random seed and no. of features for tfidf\n",
        "np.random.seed(seed)\n",
        "number_of_features = 2500\n",
        "\n",
        "# create tfidf feature vector matrix\n",
        "tfidf = TfidfVectorizer(max_features = number_of_features)\n",
        "X = tfidf.fit_transform(c_df['stop']).toarray()\n",
        "y = c_df['Label'].values\n",
        "\n",
        "# append other features to tfidf feature matrix\n",
        "print(type(X),X.shape,X[1])\n",
        "X=np.column_stack((X,features_arr))\n",
        "print(type(X),X.shape,X[1])\n",
        "\n",
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X[:-len(test_df['Text'])], y[:-len(test_df['Text'])], test_size = split_ratio, random_state = seed)\n",
        "\n",
        "# oversampling training data using SMOTE\n",
        "print(type(X_train),X_train.shape,X_train[1])\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 2)\n",
        "X_train, y_train = sm.fit_resample(X_train, y_train.ravel())\n",
        "print(type(X_train),X_train.shape,X_train[1])\n",
        "\n",
        "X_iclr=X[-len(test_df['Text']):]\n",
        "y_iclr=y[-len(test_df['Text']):]\n",
        "\n",
        "\n",
        "print(\"\\n\\n-----------------------------------------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "# hyperparameters\n",
        "epochs = 5\n",
        "batch_size = 15\n",
        "learning_rate = 1e-3\n",
        "dropout_rate = 0.2\n",
        "verbose=1\n",
        "\n",
        "precision = tf.keras.metrics.Precision()\n",
        "recall = tf.keras.metrics.Recall()\n",
        "adam = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "\n",
        "# Start neural network\n",
        "network = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=24, activation='relu', input_shape=(number_of_features+features_arr.shape[1],)))\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=20, activation='relu'))\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# Compile neural network\n",
        "network.compile(loss='binary_crossentropy', # Cross-entropy\n",
        "                optimizer=adam, # Root Mean Square Propagation\n",
        "                metrics=['accuracy']) # Accuracy performance metric\n",
        "network.summary()\n",
        "\n",
        "\n",
        "# Train neural network\n",
        "history = network.fit(X_train, # Features\n",
        "                      y_train, # Target vector\n",
        "                      epochs=epochs, # Number of epochs\n",
        "                      verbose=verbose, # Print description after each epoch\n",
        "                      batch_size=batch_size) # Number of observations per batch\n",
        "                      # validation_data=(X_test, y_test)) # Data for evaluation\n",
        "\n",
        "print(\"\\n\\n-----------------------------------------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "\"\"\"FNN BASELINE\"\"\"\n",
        "print(\"\\n\\nFNN Baseline\")\n",
        "\n",
        "prediction = network.predict(X_test)\n",
        "for i in range(len(prediction)):\n",
        "  if prediction[i]>=0.5:\n",
        "    prediction[i]=1\n",
        "  else:\n",
        "    prediction[i]=0\n",
        "accuracy_score(y_test,prediction)\n",
        "print(np.transpose(prediction),accuracy_score(y_test,prediction))\n",
        "\n",
        "print(y_test)\n",
        "\n",
        "comparison.append(('FNN',accuracy_score(y_test,prediction)))\n",
        "print(\"accuracy: \",accuracy_score(y_test,prediction))\n",
        "print(\"precision: \",precision_score(y_test,prediction))\n",
        "print(\"f1 score: \",f1_score(y_test,prediction))\n",
        "print(\"recall: \",recall_score(y_test,prediction))\n",
        "print(\"roc_auc score: \",roc_auc_score(y_test,prediction))\n",
        "\n",
        "\n",
        "\"\"\"FNN QUALITATIVE ANALYSIS\"\"\"\n",
        "print(\"\\n\\nFNN Qualitative\")\n",
        "\n",
        "pred_iclr = network.predict(X_iclr)\n",
        "for i in range(len(pred_iclr)):\n",
        "  if pred_iclr[i]>=0.5:\n",
        "    pred_iclr[i]=1\n",
        "  else:\n",
        "    pred_iclr[i]=0\n",
        "accuracy_score(y_iclr,pred_iclr)\n",
        "print(np.transpose(pred_iclr),accuracy_score(y_iclr,pred_iclr))\n",
        "\n",
        "print(y_iclr)\n",
        "\n",
        "qualitative.append(('FNN',accuracy_score(y_iclr,pred_iclr)))\n",
        "print(\"accuracy: \",accuracy_score(y_iclr,pred_iclr))\n",
        "print(\"precision: \",precision_score(y_iclr,pred_iclr))\n",
        "print(\"f1 score: \",f1_score(y_iclr,pred_iclr))\n",
        "print(\"recall: \",recall_score(y_iclr,pred_iclr))\n",
        "print(\"roc_auc score: \",roc_auc_score(y_iclr,pred_iclr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWpas_rHv1uC",
        "outputId": "cbb6109d-ff5e-4262-92d7-d3f9d82374f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "<class 'numpy.ndarray'> (1516, 2500) [0. 0. 0. ... 0. 0. 0.]\n",
            "<class 'numpy.ndarray'> (1516, 2516) [0.         0.         0.         ... 0.00013358 0.00017784 0.00014292]\n",
            "<class 'numpy.ndarray'> (1196, 2516) [0.         0.         0.         ... 0.00011524 0.00017741 0.00014336]\n",
            "<class 'numpy.ndarray'> (1202, 2516) [0.         0.         0.         ... 0.00011524 0.00017741 0.00014336]\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 24)                60408     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 20)                500       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,929\n",
            "Trainable params: 60,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "81/81 [==============================] - 1s 5ms/step - loss: 0.6889 - accuracy: 0.5316\n",
            "Epoch 2/5\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.6569 - accuracy: 0.6273\n",
            "Epoch 3/5\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.5994 - accuracy: 0.7146\n",
            "Epoch 4/5\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.7804\n",
            "Epoch 5/5\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.8502\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "FNN Baseline\n",
            "[[0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            "  0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1.\n",
            "  1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0.\n",
            "  0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
            "  0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0.\n",
            "  1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0.\n",
            "  0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            "  0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
            "  0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "  1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.\n",
            "  0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1.\n",
            "  1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0.]] 0.75\n",
            "[0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0\n",
            " 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1\n",
            " 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 0\n",
            " 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0\n",
            " 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0\n",
            " 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1\n",
            " 1 1 0 0]\n",
            "accuracy:  0.75\n",
            "precision:  0.8173913043478261\n",
            "f1 score:  0.7148288973384029\n",
            "recall:  0.6351351351351351\n",
            "roc_auc score:  0.7484886201991465\n",
            "\n",
            "\n",
            "FNN Qualitative\n",
            "[[0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1.]] 0.85\n",
            "[0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1]\n",
            "accuracy:  0.85\n",
            "precision:  1.0\n",
            "f1 score:  0.8235294117647058\n",
            "recall:  0.7\n",
            "roc_auc score:  0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# size of features and labels for train, test(baseline) and iclr\n",
        "print(X.shape, y.shape)\n",
        "print(X_train.shape, X_test.shape, X_iclr.shape)\n",
        "print(y_train.shape, y_test.shape, y_iclr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHMCZom1wt1u",
        "outputId": "e52b8f8c-304e-4bc6-e438-53fff1bf52eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1516, 2516) (1516,)\n",
            "(1202, 2516) (300, 2516) (20, 2516)\n",
            "(1202,) (300,) (20,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "APPEND\n",
        "\"\"\"\n",
        "model_name.append(\"FNN\")\n",
        "\n",
        "#test\n",
        "acc_t = acc_test.append(accuracy_score(y_test,prediction))\n",
        "auc_t = auc_test.append(roc_auc_score(y_test,prediction))\n",
        "prec_t = prec_test.append(precision_score(y_test,prediction))\n",
        "rec_t = rec_test.append(recall_score(y_test,prediction))\n",
        "f1_t = f1_test.append(f1_score(y_test,prediction))\n",
        "\n",
        "#iclr\n",
        "acc_i = acc_iclr.append(accuracy_score(y_iclr,pred_iclr))\n",
        "auc_i = auc_iclr.append(roc_auc_score(y_iclr,pred_iclr))\n",
        "prec_i = prec_iclr.append(precision_score(y_iclr,pred_iclr))\n",
        "rec_i = rec_iclr.append(recall_score(y_iclr,pred_iclr))\n",
        "f1_i = f1_iclr.append(f1_score(y_iclr,pred_iclr))\n",
        "\n",
        "FNN_res=[accuracy_score(y_test,prediction),accuracy_score(y_iclr,pred_iclr),roc_auc_score(y_test,prediction),roc_auc_score(y_iclr,pred_iclr),\n",
        "          precision_score(y_test,prediction),precision_score(y_iclr,pred_iclr),recall_score(y_test,prediction),recall_score(y_iclr,pred_iclr),\n",
        "          f1_score(y_test,prediction),f1_score(y_iclr,pred_iclr)]"
      ],
      "metadata": {
        "id": "OrVMBMjRwyyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "UNIVERSAL SENTENCE ENCODER\n",
        "\"\"\"\n",
        "# import necessary libraries\n",
        "import tensorflow_hub as hub\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "\n",
        "# Load pre-trained universal sentence encoder model\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hibaT4kNwzxb",
        "outputId": "c80830f7-1aba-47c4-cb11-2dfbb9260800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create USE embeddings from review sentences\n",
        "Sentences = []\n",
        "labels = []\n",
        "with open(\"/content/drive/MyDrive/ML/innovation_lab/Final_review_dataset.csv\", 'r', encoding=\"unicode_escape\") as csvfile: # SOURCE PATH FOR REVIEW DATASET\n",
        "  dataset = csv.reader(csvfile)\n",
        "  next(dataset, None)\n",
        "  for item in dataset:\n",
        "    if (item[1] == 'C'):\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      labels.append(0)\n",
        "    Sentences.append(item[0])\n",
        "Sentences.extend(test_sent)\n",
        "for i in test_sent_labels:\n",
        "  if i=='C':\n",
        "    labels.append(1)\n",
        "  else:\n",
        "    labels.append(0)\n",
        "\n",
        "# print(Sentences)\n",
        "# print(labels)\n",
        "print(len(Sentences))\n",
        "print(len(labels))\n",
        "\n",
        "sentence_embeddings = embed(Sentences)\n",
        "\n",
        " \n",
        "# append other features to USE embedding matrix\n",
        "print(type(sentence_embeddings),sentence_embeddings.shape)\n",
        "sentence_embeddings=np.column_stack((sentence_embeddings,features_arr))\n",
        "print(type(sentence_embeddings),sentence_embeddings.shape)\n",
        "\n",
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "training_embeddings, testing_embeddings, training_labels, testing_labels = train_test_split(sentence_embeddings[:-len(test_df['Text'])], labels[:-len(test_df['Text'])], test_size = split_ratio, random_state = seed)\n",
        "\n",
        "# oversampling training data using SMOTE\n",
        "print(type(training_embeddings),training_embeddings.shape)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 2)\n",
        "training_embeddings, training_labels = sm.fit_resample(training_embeddings, training_labels)\n",
        "print(type(training_embeddings),training_embeddings.shape)\n",
        "\n",
        "# obtain iclr data\n",
        "iclr_embeddings=sentence_embeddings[-len(test_df['Text']):]\n",
        "iclr_labels=labels[-len(test_df['Text']):]\n",
        "\n",
        "# reshaping feature matrix to fit into our model\n",
        "print(training_embeddings.shape, testing_embeddings.shape, iclr_embeddings.shape)\n",
        "training_embeddings = np.reshape(training_embeddings, (training_embeddings.shape[0], 1, training_embeddings.shape[1]))\n",
        "testing_embeddings = np.reshape(testing_embeddings, (testing_embeddings.shape[0], 1, testing_embeddings.shape[1]))\n",
        "iclr_embeddings = np.reshape(iclr_embeddings, (iclr_embeddings.shape[0], 1, iclr_embeddings.shape[1]))\n",
        "print(training_embeddings.shape, testing_embeddings.shape, iclr_embeddings.shape)\n",
        "\n",
        "training_embeddings = np.array(training_embeddings)\n",
        "training_labels = np.array(training_labels)\n",
        "testing_embeddings = np.array(testing_embeddings)\n",
        "testing_labels = np.array(testing_labels)\n",
        "\n",
        "\n",
        "print(\"\\n\\n--------------------------------------------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "# hyperparameters\n",
        "epochs = 5\n",
        "batch_size = 15\n",
        "learning_rate = 1e-3\n",
        "dropout_rate = 0.2\n",
        "verbose=1\n",
        "\n",
        "precision = tf.keras.metrics.Precision()\n",
        "recall = tf.keras.metrics.Recall()\n",
        "adam = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# setting up the model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32), input_shape=(1,512+features_arr.shape[1])),\n",
        "  tf.keras.layers.Dropout(dropout_rate),\n",
        "  tf.keras.layers.Dense(24, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropout_rate),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(training_embeddings, training_labels, epochs=epochs, verbose=verbose, batch_size=batch_size)\n",
        "\n",
        "print(\"\\n\\n--------------------------------------------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "# function to find prediction label\n",
        "def find_result(test_emb):\n",
        "  pred=[]\n",
        "  for emb in test_emb:\n",
        "    sentence_embedding = np.array([emb])\n",
        "    result=model.predict(sentence_embedding)\n",
        "    result=round(result[0][0])\n",
        "    pred.append(result)\n",
        "  return pred\n",
        "\n",
        "\n",
        "\"\"\"USE BASELINE\"\"\"\n",
        "print(\"\\n\\nUSE Baseline\")\n",
        "\n",
        "prediction = find_result(testing_embeddings)\n",
        "accuracy_score(testing_labels,prediction)\n",
        "print(prediction,accuracy_score(testing_labels,prediction))\n",
        "\n",
        "\n",
        "print(testing_labels)\n",
        "\n",
        "comparison.append(('USE',accuracy_score(testing_labels,prediction)))\n",
        "print(\"accuracy: \",accuracy_score(testing_labels,prediction))\n",
        "print(\"precision: \",precision_score(testing_labels,prediction))\n",
        "print(\"f1 score: \",f1_score(testing_labels,prediction))\n",
        "print(\"recall: \",recall_score(testing_labels,prediction))\n",
        "print(\"roc_auc score: \",roc_auc_score(testing_labels,prediction))\n",
        "\n",
        "\n",
        "\"\"\"USE QUALITATIVE ANALYSIS\"\"\"\n",
        "print(\"\\n\\nUSE Qualitative\")\n",
        "\n",
        "pred_iclr = find_result(iclr_embeddings)\n",
        "accuracy_score(iclr_labels,pred_iclr)\n",
        "print(pred_iclr,accuracy_score(iclr_labels,pred_iclr))\n",
        "\n",
        "print(iclr_labels)\n",
        "\n",
        "qualitative.append(('USE',accuracy_score(iclr_labels,pred_iclr)))\n",
        "print(\"accuracy: \",accuracy_score(iclr_labels,pred_iclr))\n",
        "print(\"precision: \",precision_score(iclr_labels,pred_iclr))\n",
        "print(\"f1 score: \",f1_score(iclr_labels,pred_iclr))\n",
        "print(\"recall: \",recall_score(iclr_labels,pred_iclr))\n",
        "print(\"roc_auc score: \",roc_auc_score(iclr_labels,pred_iclr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCrAh8F4w4Sb",
        "outputId": "b9c98870-d4a4-46c3-c4ec-701b06b8537f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1516\n",
            "1516\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'> (1516, 512)\n",
            "<class 'numpy.ndarray'> (1516, 528)\n",
            "<class 'numpy.ndarray'> (1196, 528)\n",
            "<class 'numpy.ndarray'> (1202, 528)\n",
            "(1202, 528) (300, 528) (20, 528)\n",
            "(1202, 1, 528) (300, 1, 528) (20, 1, 528)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirectio  (None, 64)               143616    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 24)                1560      \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 24)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 145,201\n",
            "Trainable params: 145,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "81/81 [==============================] - 4s 10ms/step - loss: 0.6724 - accuracy: 0.5923 - precision_7: 0.5855 - recall_7: 0.6323\n",
            "Epoch 2/5\n",
            "81/81 [==============================] - 1s 10ms/step - loss: 0.6208 - accuracy: 0.6722 - precision_7: 0.6913 - recall_7: 0.6223\n",
            "Epoch 3/5\n",
            "81/81 [==============================] - 1s 9ms/step - loss: 0.5357 - accuracy: 0.7346 - precision_7: 0.7573 - recall_7: 0.6905\n",
            "Epoch 4/5\n",
            "81/81 [==============================] - 1s 9ms/step - loss: 0.4811 - accuracy: 0.7704 - precision_7: 0.7886 - recall_7: 0.7388\n",
            "Epoch 5/5\n",
            "81/81 [==============================] - 1s 9ms/step - loss: 0.4586 - accuracy: 0.7912 - precision_7: 0.8028 - recall_7: 0.7720\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "USE Baseline\n",
            "[0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0] 0.7566666666666667\n",
            "[0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0\n",
            " 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1\n",
            " 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 0\n",
            " 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0\n",
            " 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0\n",
            " 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1\n",
            " 1 1 0 0]\n",
            "accuracy:  0.7566666666666667\n",
            "precision:  0.711864406779661\n",
            "f1 score:  0.7753846153846154\n",
            "recall:  0.8513513513513513\n",
            "roc_auc score:  0.7579125177809388\n",
            "\n",
            "\n",
            "USE Qualitative\n",
            "[1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1] 0.9\n",
            "[0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1]\n",
            "accuracy:  0.9\n",
            "precision:  0.8333333333333334\n",
            "f1 score:  0.9090909090909091\n",
            "recall:  1.0\n",
            "roc_auc score:  0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# size of features and labels for train, test(baseline) and iclr\n",
        "print(sentence_embeddings.shape, len(labels))\n",
        "print(training_embeddings.shape, testing_embeddings.shape, iclr_embeddings.shape)\n",
        "print(training_labels.shape, testing_labels.shape, len(iclr_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3BoSy526c_U",
        "outputId": "d4c5d0d9-6899-4c6c-e3a6-4d1d7ad7179c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1516, 528) 1516\n",
            "(1202, 1, 528) (300, 1, 528) (20, 1, 528)\n",
            "(1202,) (300,) 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "APPEND\n",
        "\"\"\"\n",
        "model_name.append(\"USE\")\n",
        "\n",
        "#test\n",
        "acc_t = acc_test.append(accuracy_score(testing_labels,prediction))\n",
        "auc_t = auc_test.append(roc_auc_score(testing_labels,prediction))\n",
        "prec_t = prec_test.append(precision_score(testing_labels,prediction))\n",
        "rec_t = rec_test.append(recall_score(testing_labels,prediction))\n",
        "f1_t = f1_test.append(f1_score(testing_labels,prediction))\n",
        "\n",
        "#iclr\n",
        "acc_i = acc_iclr.append(accuracy_score(iclr_labels,pred_iclr))\n",
        "auc_i = auc_iclr.append(roc_auc_score(iclr_labels,pred_iclr))\n",
        "prec_i = prec_iclr.append(precision_score(iclr_labels,pred_iclr))\n",
        "rec_i = rec_iclr.append(recall_score(iclr_labels,pred_iclr))\n",
        "f1_i = f1_iclr.append(f1_score(iclr_labels,pred_iclr))\n",
        "\n",
        "USE_res=[accuracy_score(testing_labels,prediction),accuracy_score(iclr_labels,pred_iclr),roc_auc_score(testing_labels,prediction),roc_auc_score(iclr_labels,pred_iclr),\n",
        "          precision_score(testing_labels,prediction),precision_score(iclr_labels,pred_iclr),recall_score(testing_labels,prediction),recall_score(iclr_labels,pred_iclr),\n",
        "          f1_score(testing_labels,prediction),f1_score(iclr_labels,pred_iclr)]"
      ],
      "metadata": {
        "id": "dgp0pstN6jWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "BERT + biLSTM\n",
        "\"\"\"\n",
        "# import necessary libraries\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "# create BERT sentence embeddings\n",
        "sentences = []\n",
        "labels = []\n",
        "with open(\"/content/drive/MyDrive/ML/innovation_lab/Final_review_dataset.csv\", 'r', encoding=\"unicode_escape\") as csvfile: # SOURCE PATH FOR REVIEW DATASET\n",
        "  dataset = csv.reader(csvfile)\n",
        "  next(dataset, None)\n",
        "  i = 0\n",
        "  for item in dataset:\n",
        "    if (item[1] == 'C'):\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      labels.append(0)\n",
        "    sentences.append(item[0])\n",
        "sentences.extend(test_sent)\n",
        "for i in test_sent_labels:\n",
        "  if i=='C':\n",
        "    labels.append(1)\n",
        "  else:\n",
        "    labels.append(0)\n",
        "\n",
        "# print(sentences)\n",
        "# print(labels)\n",
        "print(len(sentences))\n",
        "print(len(labels))\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "encoder = TFBertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
        "\n",
        "sentence_embeddings = []\n",
        "for sentence in sentences:\n",
        "  encoded_input = tokenizer(sentence, return_tensors='tf')\n",
        "  output = encoder(encoded_input)\n",
        "  token_embeddings = output.hidden_states\n",
        "  token_embeddings = tf.squeeze(token_embeddings)\n",
        "  token_embeddings = tf.transpose(token_embeddings, perm=[1, 0, 2])\n",
        "  sentence_embedding = tf.reduce_mean(token_embeddings, 0)[1:]\n",
        "  sentence_embeddings.append(sentence_embedding)\n",
        "print(len(sentence_embeddings))\n",
        "\n",
        "# append other features to BERT embedding feature matrix\n",
        "print(type(sentence_embeddings[1]),sentence_embeddings[1].shape)\n",
        "for i in range(len(sentence_embeddings)):\n",
        "  sentence_embeddings[i]=np.column_stack((sentence_embeddings[i], np.repeat(np.reshape(features_arr[i], (1, features_arr[i].shape[0])), [sentence_embeddings[i].shape[0]], axis=0)))\n",
        "print(type(sentence_embeddings[1]),sentence_embeddings[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lRyoSM_6pmF",
        "outputId": "74b0ec17-17bb-4b2a-d0d3-7b25b4fa4757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "1516\n",
            "1516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1516\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'> (12, 768)\n",
            "<class 'numpy.ndarray'> (12, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "training_embeddings, testing_embeddings, training_labels, testing_labels = train_test_split(sentence_embeddings[:-len(test_df['Text'])], labels[:-len(test_df['Text'])], test_size = split_ratio, random_state = seed)\n",
        "\n",
        "\n",
        "training_embeddings = np.array(training_embeddings)\n",
        "training_labels = np.array(training_labels)\n",
        "testing_embeddings = np.array(testing_embeddings)\n",
        "testing_labels = np.array(testing_labels)\n",
        "iclr_embeddings = np.array(sentence_embeddings[-len(test_df['Text']):])\n",
        "iclr_labels = np.array(labels[-len(test_df['Text']):])\n",
        "\n",
        "#undersampling training dataset using random under sampler\n",
        "print(training_embeddings.shape, training_labels.shape)\n",
        "from imblearn.under_sampling import RandomUnderSampler \n",
        "from collections import Counter\n",
        "rus = RandomUnderSampler(random_state=2)\n",
        "emb_idx=[]\n",
        "for i in training_embeddings:\n",
        "  for j in range(len(sentence_embeddings)):\n",
        "    if (i==sentence_embeddings[j]).all():\n",
        "      emb_idx.append(j)\n",
        "X=[]\n",
        "y=[]\n",
        "for i in emb_idx:\n",
        "  X.append(sentences[i])\n",
        "  y.append(labels[i])\n",
        "X=np.array(X).reshape(-1, 1)\n",
        "X, training_labels = rus.fit_resample(X, y)\n",
        "print('Resampled dataset shape %s' % Counter(training_labels))\n",
        "emb_idx=[]\n",
        "for i in X:\n",
        "  for j in range(len(sentences)):\n",
        "    if i[0]==sentences[j]:\n",
        "      emb_idx.append(j)\n",
        "training_embeddings=[]\n",
        "for i in emb_idx:\n",
        "  training_embeddings.append(sentence_embeddings[i])\n",
        "training_embeddings = np.array(training_embeddings)\n",
        "training_labels = np.array(training_labels)\n",
        "print(training_embeddings.shape, training_labels.shape)\n",
        "\n",
        "\n",
        "print(\"\\n\\n--------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "# hyperparameters\n",
        "epochs = 5\n",
        "batch_size = 15\n",
        "learning_rate = 1e-3\n",
        "dropout_rate = 0.2\n",
        "verbose = 1\n",
        "\n",
        "precision = tf.keras.metrics.Precision()\n",
        "recall = tf.keras.metrics.Recall()\n",
        "adam = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# setting up the model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32), input_shape=(12, 768+features_arr.shape[1])),\n",
        "  tf.keras.layers.Dropout(dropout_rate),\n",
        "  tf.keras.layers.Dense(24, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropout_rate),\n",
        "  tf.keras.layers.Dense(24, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropout_rate),\n",
        "  tf.keras.layers.Dense(24, activation='relu'),\n",
        "  tf.keras.layers.Dropout(dropout_rate),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(training_embeddings, training_labels, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
        "\n",
        "print(\"\\n\\n--------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "# function to give predicted labels\n",
        "def find_result(test_emb):\n",
        "  pred=[]\n",
        "  for emb in test_emb:\n",
        "    sentence_embedding = np.array([emb])\n",
        "    result=model.predict(sentence_embedding)\n",
        "    result=round(result[0][0])\n",
        "    pred.append(result)\n",
        "  return pred\n",
        "\n",
        "\n",
        "\"\"\"BERT BASELINE\"\"\"\n",
        "print(\"\\n\\nBERT Baseline\")\n",
        "\n",
        "prediction = find_result(testing_embeddings)\n",
        "accuracy_score(testing_labels,prediction)\n",
        "print(prediction,accuracy_score(testing_labels,prediction))\n",
        "\n",
        "\n",
        "print(testing_labels)\n",
        "\n",
        "comparison.append(('BERT',accuracy_score(testing_labels,prediction)))\n",
        "print(\"accuracy: \",accuracy_score(testing_labels,prediction))\n",
        "print(\"precision: \",precision_score(testing_labels,prediction))\n",
        "print(\"f1 score: \",f1_score(testing_labels,prediction))\n",
        "print(\"recall: \",recall_score(testing_labels,prediction))\n",
        "print(\"roc_auc score: \",roc_auc_score(testing_labels,prediction))\n",
        "\n",
        "\n",
        "\"\"\"BERT QUALITATIVE ANALYSIS\"\"\"\n",
        "print(\"\\n\\nBERT Qualitative\")\n",
        "\n",
        "pred_iclr = find_result(iclr_embeddings)\n",
        "accuracy_score(iclr_labels,pred_iclr)\n",
        "print(pred_iclr,accuracy_score(iclr_labels,pred_iclr))\n",
        "\n",
        "print(iclr_labels)\n",
        "\n",
        "qualitative.append(('BERT',accuracy_score(iclr_labels,pred_iclr)))\n",
        "print(\"accuracy: \",accuracy_score(iclr_labels,pred_iclr))\n",
        "print(\"precision: \",precision_score(iclr_labels,pred_iclr))\n",
        "print(\"f1 score: \",f1_score(iclr_labels,pred_iclr))\n",
        "print(\"recall: \",recall_score(iclr_labels,pred_iclr))\n",
        "print(\"roc_auc score: \",roc_auc_score(iclr_labels,pred_iclr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFbXSsoB67H3",
        "outputId": "c144d486-1cb9-42cb-eec2-a4b2921d8cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1196, 12, 784) (1196,)\n",
            "Resampled dataset shape Counter({0: 604, 1: 604})\n",
            "(1208, 12, 784) (1208,)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_3 (Bidirectio  (None, 64)               209152    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_82 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 24)                1560      \n",
            "                                                                 \n",
            " dropout_83 (Dropout)        (None, 24)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 24)                600       \n",
            "                                                                 \n",
            " dropout_84 (Dropout)        (None, 24)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 24)                600       \n",
            "                                                                 \n",
            " dropout_85 (Dropout)        (None, 24)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 211,937\n",
            "Trainable params: 211,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "81/81 [==============================] - 8s 13ms/step - loss: 0.6657 - accuracy: 0.5844 - precision_9: 0.5859 - recall_9: 0.5762\n",
            "Epoch 2/5\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 0.5598 - accuracy: 0.7301 - precision_9: 0.7235 - recall_9: 0.7450\n",
            "Epoch 3/5\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.5015 - accuracy: 0.7815 - precision_9: 0.7787 - recall_9: 0.7864\n",
            "Epoch 4/5\n",
            "81/81 [==============================] - 1s 11ms/step - loss: 0.4615 - accuracy: 0.7873 - precision_9: 0.7849 - recall_9: 0.7914\n",
            "Epoch 5/5\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.4131 - accuracy: 0.8146 - precision_9: 0.8125 - recall_9: 0.8179\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "BERT Baseline\n",
            "[0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0] 0.7833333333333333\n",
            "[0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0\n",
            " 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1\n",
            " 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 0\n",
            " 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0\n",
            " 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0\n",
            " 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1\n",
            " 1 1 0 0]\n",
            "accuracy:  0.7833333333333333\n",
            "precision:  0.7643312101910829\n",
            "f1 score:  0.7868852459016394\n",
            "recall:  0.8108108108108109\n",
            "roc_auc score:  0.783694879089616\n",
            "\n",
            "\n",
            "BERT Qualitative\n",
            "[0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1] 0.95\n",
            "[0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1]\n",
            "accuracy:  0.95\n",
            "precision:  1.0\n",
            "f1 score:  0.9473684210526316\n",
            "recall:  0.9\n",
            "roc_auc score:  0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# size of features and labels for train, test(baseline) and iclr\n",
        "print(len(sentence_embeddings),sentence_embeddings[0].shape, len(labels))\n",
        "print(training_embeddings.shape, testing_embeddings.shape, iclr_embeddings.shape)\n",
        "print(training_labels.shape, testing_labels.shape, len(iclr_labels))"
      ],
      "metadata": {
        "id": "JM94C8Vt7d8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177af079-febe-43bd-f7ff-32092d983f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1516 (12, 784) 1516\n",
            "(1208, 12, 784) (300, 12, 784) (20, 12, 784)\n",
            "(1208,) (300,) 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "APPEND\n",
        "\"\"\"\n",
        "model_name.append(\"BERT\")\n",
        "\n",
        "#test\n",
        "acc_t = acc_test.append(accuracy_score(testing_labels,prediction))\n",
        "auc_t = auc_test.append(roc_auc_score(testing_labels,prediction))\n",
        "prec_t = prec_test.append(precision_score(testing_labels,prediction))\n",
        "rec_t = rec_test.append(recall_score(testing_labels,prediction))\n",
        "f1_t = f1_test.append(f1_score(testing_labels,prediction))\n",
        "\n",
        "#iclr\n",
        "acc_i = acc_iclr.append(accuracy_score(iclr_labels,pred_iclr))\n",
        "auc_i = auc_iclr.append(roc_auc_score(iclr_labels,pred_iclr))\n",
        "prec_i = prec_iclr.append(precision_score(iclr_labels,pred_iclr))\n",
        "rec_i = rec_iclr.append(recall_score(iclr_labels,pred_iclr))\n",
        "f1_i = f1_iclr.append(f1_score(iclr_labels,pred_iclr))\n",
        "\n",
        "BERT_res=[accuracy_score(testing_labels,prediction),accuracy_score(iclr_labels,pred_iclr),roc_auc_score(testing_labels,prediction),roc_auc_score(iclr_labels,pred_iclr),\n",
        "          precision_score(testing_labels,prediction),precision_score(iclr_labels,pred_iclr),recall_score(testing_labels,prediction),recall_score(iclr_labels,pred_iclr),\n",
        "          f1_score(testing_labels,prediction),f1_score(iclr_labels,pred_iclr)]"
      ],
      "metadata": {
        "id": "SREcP6TK7kcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "CfuAZx547vlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f104b184-fc78-40dd-f40c-6543b55ae90a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML/innovation_lab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "RESULTS\n",
        "\"\"\"\n",
        "\n",
        "print(\"model_name: {} \\nacc_test: {} \\nacc_iclr: {} \\nauc_test: {} \\nauc_iclr: {} \\nprec_test: {} \\nprec_iclr: {} \\nrec_test: {} \\nrec_iclr: {} \\nf1_test: {} \\nf1_iclr: {}\"\n",
        ".format(model_name,acc_test,acc_iclr,auc_test,auc_iclr,prec_test,prec_iclr,rec_test,rec_iclr,f1_test,f1_iclr))\n",
        "\n",
        "print(\"\\n\\nSVC_res= {} \\nMNB_res= {} \\nXGB_res= {} \\nFNN_res= {} \\nUSE_res= {} \\nBERT_res= {}\".format(SVC_res,MNB_res,XGB_res,FNN_res,USE_res,BERT_res))"
      ],
      "metadata": {
        "id": "FxBbWY5E700j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80df5138-2fb3-4960-c847-4872a5e0af4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name: ['Support Vector Classifier', 'Multinomial Naive Bayes', 'XGBoost', 'FNN', 'USE', 'BERT'] \n",
            "acc_test: [0.75, 0.7466666666666667, 0.7733333333333333, 0.75, 0.7566666666666667, 0.7833333333333333] \n",
            "acc_iclr: [0.9, 0.95, 0.75, 0.85, 0.9, 0.95] \n",
            "auc_test: [0.7495554765291608, 0.7479551920341395, 0.7737375533428165, 0.7484886201991465, 0.7579125177809388, 0.783694879089616] \n",
            "auc_iclr: [0.9, 0.95, 0.7500000000000001, 0.85, 0.9, 0.95] \n",
            "prec_test: [0.762589928057554, 0.702247191011236, 0.7531645569620253, 0.8173913043478261, 0.711864406779661, 0.7643312101910829] \n",
            "prec_iclr: [1.0, 1.0, 0.8571428571428571, 1.0, 0.8333333333333334, 1.0] \n",
            "rec_test: [0.7162162162162162, 0.8445945945945946, 0.8040540540540541, 0.6351351351351351, 0.8513513513513513, 0.8108108108108109] \n",
            "rec_iclr: [0.8, 0.9, 0.6, 0.7, 1.0, 0.9] \n",
            "f1_test: [0.7386759581881532, 0.7668711656441718, 0.7777777777777778, 0.7148288973384029, 0.7753846153846154, 0.7868852459016394] \n",
            "f1_iclr: [0.888888888888889, 0.9473684210526316, 0.7058823529411764, 0.8235294117647058, 0.9090909090909091, 0.9473684210526316]\n",
            "\n",
            "\n",
            "SVM_res= [0.75, 0.9, 0.7495554765291608, 0.9, 0.762589928057554, 1.0, 0.7162162162162162, 0.8, 0.7386759581881532, 0.888888888888889] \n",
            "MNB_res= [0.7466666666666667, 0.95, 0.7479551920341395, 0.95, 0.702247191011236, 1.0, 0.8445945945945946, 0.9, 0.7668711656441718, 0.9473684210526316] \n",
            "XGB_res= [0.7733333333333333, 0.75, 0.7737375533428165, 0.7500000000000001, 0.7531645569620253, 0.8571428571428571, 0.8040540540540541, 0.6, 0.7777777777777778, 0.7058823529411764] \n",
            "FNN_res= [0.75, 0.85, 0.7484886201991465, 0.85, 0.8173913043478261, 1.0, 0.6351351351351351, 0.7, 0.7148288973384029, 0.8235294117647058] \n",
            "USE_res= [0.7566666666666667, 0.9, 0.7579125177809388, 0.9, 0.711864406779661, 0.8333333333333334, 0.8513513513513513, 1.0, 0.7753846153846154, 0.9090909090909091] \n",
            "BERT_res= [0.7833333333333333, 0.95, 0.783694879089616, 0.95, 0.7643312101910829, 1.0, 0.8108108108108109, 0.9, 0.7868852459016394, 0.9473684210526316]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "PERFORMANCE GRAPH\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# score_list=[model_name,acc_train,acc_test,auc_train,auc_test,prec_train,prec_test,rec_train,rec_test,f1_train,f1_test]\n",
        "data_keys = ['Accuracy_baseline', 'Accuracy_iclr', 'AUC_baseline', 'AUC_iclr', 'Precision_baseline', 'Precision_iclr', 'Recall_baseline', 'Recall_iclr', 'f1 score_baseline', 'f1 score_iclr']\n",
        "labels=['SVC', 'MNB', 'XGBoost','FNN', 'USE', 'BERT']\n",
        "\n",
        "data_lst=[SVC_res,MNB_res,XGB_res,FNN_res,USE_res,BERT_res]\n",
        "for model_x in data_lst:\n",
        "  for num in range(len(model_x)):\n",
        "    model_x[num]=round(model_x[num],4)\n",
        "\n",
        "X = np.arange(len(data_lst[0]))\n",
        "fig, ax = plt.subplots(figsize=(16,5))\n",
        "# fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(X + 0.00, data_lst[0], color = '#4f6d7a', width = 0.15)\n",
        "ax.bar(X + 0.15, data_lst[1], color = '#ff595e', width = 0.15)\n",
        "ax.bar(X + 0.30, data_lst[2], color = '#ffca3a', width = 0.15)\n",
        "ax.bar(X + 0.45, data_lst[3], color = '#8ac926', width = 0.15)\n",
        "ax.bar(X + 0.60, data_lst[4], color = '#1982c4', width = 0.15)\n",
        "ax.bar(X + 0.75, data_lst[5], color = '#6a4c93', width = 0.15)\n",
        "ax.legend(labels,prop=dict(weight='bold'))\n",
        "ax.set_ylabel('score',size='15',fontweight='bold')\n",
        "# ax.set_xlabel('section',size='15',fontweight='bold')\n",
        "ax.set_xticks(X+0.375)\n",
        "ax.set_xticklabels(data_keys,fontweight='bold')\n",
        "plt.xticks(rotation=45)\n",
        "pps = [ax.bar(X + 0.00, data_lst[0], color = '#4f6d7a', width = 0.15),\n",
        "ax.bar(X + 0.15, data_lst[1], color = '#ff595e', width = 0.15),\n",
        "ax.bar(X + 0.30, data_lst[2], color = '#ffca3a', width = 0.15),\n",
        "ax.bar(X + 0.45, data_lst[3], color = '#8ac926', width = 0.15),\n",
        "ax.bar(X + 0.60, data_lst[4], color = '#1982c4', width = 0.15),\n",
        "ax.bar(X + 0.75, data_lst[5], color = '#6a4c93', width = 0.15)]\n",
        "# for item in pps:\n",
        "#   for p in item:\n",
        "#     height = p.get_height()\n",
        "#     ax.annotate('{}'.format(height),\n",
        "#         xy=(p.get_x() + p.get_width() / 2, height),\n",
        "#         xytext=(0, 3), # 3 points vertical offset\n",
        "#         textcoords=\"offset points\",\n",
        "#         ha='center', va='bottom',rotation=60)\n",
        "fig.savefig(\"/content/drive/MyDrive/ML/innovation_lab/CN_TESTING_model_dist\", bbox_inches='tight',pad_inches=0.1) # SAVE PATH FOR GRAPH\n",
        "plt.show()\n",
        "plt.clf()"
      ],
      "metadata": {
        "id": "jMFlybJv73jP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "7cd4f8d0-6042-4fd1-def5-5b3661365fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "PERFORMANCE GRAPH (BASELINE)\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# score_list=[model_name,acc_train,acc_test,auc_train,auc_test,prec_train,prec_test,rec_train,rec_test,f1_train,f1_test]\n",
        "data_keys = ['Accuracy_baseline', 'AUC_baseline', 'Precision_baseline', 'Recall_baseline', 'f1 score_baseline']\n",
        "labels=['SVC', 'MNB', 'XGBoost','FNN', 'USE', 'BERT']\n",
        "\n",
        "data_lst=[SVC_res[::2],MNB_res[::2],XGB_res[::2],FNN_res[::2],USE_res[::2],BERT_res[::2]]\n",
        "for model_x in data_lst:\n",
        "  for num in range(len(model_x)):\n",
        "    model_x[num]=round(model_x[num],4)\n",
        "\n",
        "X = np.arange(len(data_lst[0]))\n",
        "fig, ax = plt.subplots(figsize=(8,5))\n",
        "# fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(X + 0.00, data_lst[0], color = '#4f6d7a', width = 0.15)\n",
        "ax.bar(X + 0.15, data_lst[1], color = '#ff595e', width = 0.15)\n",
        "ax.bar(X + 0.30, data_lst[2], color = '#ffca3a', width = 0.15)\n",
        "ax.bar(X + 0.45, data_lst[3], color = '#8ac926', width = 0.15)\n",
        "ax.bar(X + 0.60, data_lst[4], color = '#1982c4', width = 0.15)\n",
        "ax.bar(X + 0.75, data_lst[5], color = '#6a4c93', width = 0.15)\n",
        "ax.legend(labels,prop=dict(weight='bold'),loc='lower right')\n",
        "ax.set_ylabel('score',size='15',fontweight='bold')\n",
        "# ax.set_xlabel('section',size='15',fontweight='bold')\n",
        "ax.set_xticks(X+0.375)\n",
        "ax.set_xticklabels(data_keys,fontweight='bold')\n",
        "plt.xticks(rotation=45)\n",
        "pps = [ax.bar(X + 0.00, data_lst[0], color = '#4f6d7a', width = 0.15),\n",
        "ax.bar(X + 0.15, data_lst[1], color = '#ff595e', width = 0.15),\n",
        "ax.bar(X + 0.30, data_lst[2], color = '#ffca3a', width = 0.15),\n",
        "ax.bar(X + 0.45, data_lst[3], color = '#8ac926', width = 0.15),\n",
        "ax.bar(X + 0.60, data_lst[4], color = '#1982c4', width = 0.15),\n",
        "ax.bar(X + 0.75, data_lst[5], color = '#6a4c93', width = 0.15)]\n",
        "# for item in pps:\n",
        "#   for p in item:\n",
        "#     height = p.get_height()\n",
        "#     ax.annotate('{}'.format(height),\n",
        "#         xy=(p.get_x() + p.get_width() / 2, height),\n",
        "#         xytext=(0, 3), # 3 points vertical offset\n",
        "#         textcoords=\"offset points\",\n",
        "#         ha='center', va='bottom',rotation=60)\n",
        "fig.savefig(\"/content/drive/MyDrive/ML/innovation_lab/CN_BASELINE_model_dist\", bbox_inches='tight',pad_inches=0.1) # SAVE PATH FOR GRAPH\n",
        "plt.show()\n",
        "plt.clf()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "t9bIITGtPB7F",
        "outputId": "42ff2465-ae27-4572-b86f-d9e793dcbc0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "PERFORMANCE GRAPH (QUALITATIVE ANALYSIS)\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# score_list=[model_name,acc_train,acc_test,auc_train,auc_test,prec_train,prec_test,rec_train,rec_test,f1_train,f1_test]\n",
        "data_keys = ['Accuracy_ICLR', 'AUC_ICLR', 'Precision_ICLR', 'Recall_ICLR', 'f1 score_ICLR']\n",
        "labels=['SVC', 'MNB', 'XGBoost','FNN', 'USE', 'BERT']\n",
        "\n",
        "data_lst=[SVC_res[1::2],MNB_res[1::2],XGB_res[1::2],FNN_res[1::2],USE_res[1::2],BERT_res[1::2]]\n",
        "for model_x in data_lst:\n",
        "  for num in range(len(model_x)):\n",
        "    model_x[num]=round(model_x[num],4)\n",
        "\n",
        "X = np.arange(len(data_lst[0]))\n",
        "fig, ax = plt.subplots(figsize=(8,5))\n",
        "# fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(X + 0.00, data_lst[0], color = '#4f6d7a', width = 0.15)\n",
        "ax.bar(X + 0.15, data_lst[1], color = '#ff595e', width = 0.15)\n",
        "ax.bar(X + 0.30, data_lst[2], color = '#ffca3a', width = 0.15)\n",
        "ax.bar(X + 0.45, data_lst[3], color = '#8ac926', width = 0.15)\n",
        "ax.bar(X + 0.60, data_lst[4], color = '#1982c4', width = 0.15)\n",
        "ax.bar(X + 0.75, data_lst[5], color = '#6a4c93', width = 0.15)\n",
        "ax.legend(labels,prop=dict(weight='bold'),loc='lower right')\n",
        "ax.set_ylabel('score',size='15',fontweight='bold')\n",
        "# ax.set_xlabel('section',size='15',fontweight='bold')\n",
        "ax.set_xticks(X+0.375)\n",
        "ax.set_xticklabels(data_keys,fontweight='bold')\n",
        "plt.xticks(rotation=45)\n",
        "pps = [ax.bar(X + 0.00, data_lst[0], color = '#4f6d7a', width = 0.15),\n",
        "ax.bar(X + 0.15, data_lst[1], color = '#ff595e', width = 0.15),\n",
        "ax.bar(X + 0.30, data_lst[2], color = '#ffca3a', width = 0.15),\n",
        "ax.bar(X + 0.45, data_lst[3], color = '#8ac926', width = 0.15),\n",
        "ax.bar(X + 0.60, data_lst[4], color = '#1982c4', width = 0.15),\n",
        "ax.bar(X + 0.75, data_lst[5], color = '#6a4c93', width = 0.15)]\n",
        "# for item in pps:\n",
        "#   for p in item:\n",
        "#     height = p.get_height()\n",
        "#     ax.annotate('{}'.format(height),\n",
        "#         xy=(p.get_x() + p.get_width() / 2, height),\n",
        "#         xytext=(0, 3), # 3 points vertical offset\n",
        "#         textcoords=\"offset points\",\n",
        "#         ha='center', va='bottom',rotation=60)\n",
        "fig.savefig(\"/content/drive/MyDrive/ML/innovation_lab/CN_ICLR_model_dist\", bbox_inches='tight',pad_inches=0.1) # SAVE PATH FOR GRAPH\n",
        "plt.show()\n",
        "plt.clf()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "XsJqw0NMQrR0",
        "outputId": "61d8c348-49c7-4b9c-abec-e5e61bd21538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Results:\n",
        "format = [acc_test,acc_iclr,auc_test,auc_iclr,prec_test,prec_iclr,rec_test,rec_iclr,f1_test,f1_iclr]\n",
        "SVC_res= [0.75, 0.9, 0.7495554765291608, 0.9, 0.762589928057554, 1.0, 0.7162162162162162, 0.8, 0.7386759581881532, 0.888888888888889] \n",
        "MNB_res= [0.7466666666666667, 0.95, 0.7479551920341395, 0.95, 0.702247191011236, 1.0, 0.8445945945945946, 0.9, 0.7668711656441718, 0.9473684210526316] \n",
        "XGB_res= [0.7733333333333333, 0.75, 0.7737375533428165, 0.7500000000000001, 0.7531645569620253, 0.8571428571428571, 0.8040540540540541, 0.6, 0.7777777777777778, 0.7058823529411764] \n",
        "FNN_res= [0.75, 0.85, 0.7484886201991465, 0.85, 0.8173913043478261, 1.0, 0.6351351351351351, 0.7, 0.7148288973384029, 0.8235294117647058] \n",
        "USE_res= [0.7566666666666667, 0.9, 0.7579125177809388, 0.9, 0.711864406779661, 0.8333333333333334, 0.8513513513513513, 1.0, 0.7753846153846154, 0.9090909090909091] \n",
        "BERT_res= [0.7833333333333333, 0.95, 0.783694879089616, 0.95, 0.7643312101910829, 1.0, 0.8108108108108109, 0.9, 0.7868852459016394, 0.9473684210526316]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Uf9XJLTxDC8H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
